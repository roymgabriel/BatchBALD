store = {}
store['args']={'experiment_task_id': 'resnet_multi_pretrained_random_9031', 'experiments_laaos': None, 'experiment_description': 'RSNA MULTI:RESNET BN DROPOUT RANDOM (PRETRAINED)', 'batch_size': 16, 'scoring_batch_size': 32, 'test_batch_size': 32, 'validation_set_size': 10000, 'early_stopping_patience': 3, 'epochs': 30, 'epoch_samples': 5056, 'num_inference_samples': 20, 'available_sample_k': 200, 'target_num_acquired_samples': 2500, 'target_accuracy': 0.7, 'no_cuda': False, 'quickquick': True, 'seed': 9031, 'log_interval': 20, 'initial_samples_per_class': 20, 'initial_samples': None, 'type': 'AcquisitionFunction.random', 'acquisition_method': 'AcquisitionMethod.independent', 'dataset': 'DatasetEnum.rsna_multi', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': True, 'balanced_test_set': False}
store['cmdline']=['MIP/BatchBALD/src/run_experiment.py', '--batch_size', '16', '--scoring_batch_size', '32', '--test_batch_size', '32', '--validation_set_size', '10000', '--early_stopping_patience', '3', '--epochs', '30', '--num_inference_samples', '20', '--available_sample_k', '200', '--target_num_acquired_samples', '2500', '--target_accuracy', '0.70', '--seed', '9031', '--log_interval', '20', '--initial_samples_per_class', '20', '--type', 'random', '--acquisition_method', 'independent', '--dataset', 'rsna_multi', '--balanced_validation_set', '--min_remaining_percentage', '100', '--min_candidates_per_acquired_item', '20', '--initial_percentage', '100', '--reduce_percentage', '0', '--experiment_task_id', 'resnet_multi_pretrained_random_9031', '--experiment_description', 'RSNA MULTI:RESNET BN DROPOUT RANDOM (PRETRAINED)', '--quickquick']
# store['USING REDUCED DATASET']=True
# store['Distribution of training set classes:']={1: 8226, 0: 6716, 2: 6216}
# store['Distribution of validation set classes:']={0: 83, 1: 130, 2: 89}
# store['Distribution of test set classes:']={0: 1580, 1: 1965, 2: 1455}
# store['Distribution of pool classes:']={0: 1575, 1: 1921, 2: 1444}
# store['Distribution of active set classes:']={0: 20, 1: 20, 2: 20}
# store['active samples']=60
# store['available samples']=4940
# store['validation samples']=302
# store['test samples']=5000
store['iterations']=[]
store['initial_samples']=[7374, 405, 8559, 5907, 13770, 15221, 8361, 7561, 4291, 8980, 17053, 18937, 17865, 20886, 15901, 20221, 7853, 4917, 14103, 2840, 8820, 4612, 9000, 11191, 16856, 18031, 18179, 8525, 7480, 11466, 2012, 18445, 13110, 5325, 1526, 10267, 14509, 8024, 6723, 20913, 8634, 16122, 1817, 20106, 941, 5297, 19101, 3261, 8671, 2934, 18064, 5803, 14637, 9698, 16451, 8380, 9377, 4653, 3554, 16261]
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.5962, 'nll': 1.43529677734375, 'f1': 0.6024812168464323, 'precision': 0.599533566005621, 'recall': 0.6063950819713865, 'ROC_AUC': 0.747802734375, 'PRC_AUC': 0.6167867284549792}, 'chosen_targets': [2, 1, 0, 1, 1, 2, 1, 0, 2, 2, 1, 0, 2, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 0, 1, 1, 2, 1, 0, 1, 0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 1, 1, 1, 0, 0, 0, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 1, 0, 2, 1, 0, 1, 1, 0, 1, 2, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 1], 'chosen_samples': [1257, 3394, 342, 4334, 1743, 4908, 4225, 4750, 2291, 1861, 157, 3471, 1022, 953, 3223, 2099, 3262, 146, 911, 4182, 2618, 3360, 2709, 1696, 2786, 891, 3983, 1393, 4463, 1157, 851, 1387, 2813, 4745, 4495, 2217, 1944, 4407, 1297, 4295, 1930, 3776, 2050, 3022, 35, 1985, 2631, 267, 457, 4528, 4127, 295, 1752, 1242, 892, 151, 2915, 2447, 4262, 209, 423, 2512, 784, 4013, 2091, 4291, 460, 3888, 3293, 4505, 3517, 2464, 4751, 4623, 1593, 2139, 526, 4264, 796, 3699, 710, 3813, 4180, 4791, 4500, 2444, 3334, 4838, 589, 3396, 1673, 2630, 665, 4354, 1222, 830, 3765, 3433, 3473, 112, 1437, 4107, 3631, 477, 2702, 552, 3140, 1450, 3043, 2076, 3697, 3264, 3240, 1390, 3665, 1331, 3321, 3087, 1797, 1325, 2625, 651, 1503, 486, 3160, 3647, 4790, 320, 1613, 1220, 1862, 579, 4888, 3080, 524, 3353, 3422, 212, 685, 825, 3816, 711, 2726, 4340, 3234, 565, 2350, 4296, 3289, 3536, 1376, 160, 2296, 1324, 2843, 1903, 4358, 2132, 1652, 999, 1775, 965, 2779, 4830, 4260, 2796, 4451, 2220, 1273, 1245, 349, 621, 1624, 4447, 2066, 3974, 1976, 1610, 797, 3543, 4844, 1684, 3063, 4911, 3976, 739, 564, 2550, 1777, 3811, 4485, 4631, 3565, 4321, 2901, 2752, 4174, 3345, 1228, 1702], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 161.89303762791678, 'batch_acquisition_elapsed_time': 0.0011239531449973583})
store['iterations'].append({'num_epochs': 6, 'test_metrics': {'accuracy': 0.5946, 'nll': 1.423319921875, 'f1': 0.6005612766818238, 'precision': 0.5960282216053178, 'recall': 0.6080631438179803, 'ROC_AUC': 0.766357421875, 'PRC_AUC': 0.6598509579161106}, 'chosen_targets': [0, 2, 1, 2, 0, 0, 2, 0, 1, 0, 1, 1, 2, 0, 1, 2, 0, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 0, 2, 2, 0, 0, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 0, 1, 0, 0, 2, 0, 2, 0, 2, 0, 1, 0, 2, 0, 2, 2, 1, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 0, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 2, 2, 2, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 0, 2, 2, 1, 1, 0, 1, 2, 2, 2, 1, 1, 0, 1, 1, 2, 2, 0, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 2], 'chosen_samples': [1737, 3848, 1336, 4316, 2467, 1608, 4174, 3302, 3203, 3890, 528, 4215, 1589, 3367, 3083, 3660, 1061, 3140, 807, 3970, 4060, 2333, 1554, 1429, 4168, 1946, 580, 1520, 428, 3963, 3298, 1044, 2035, 2998, 4642, 3466, 3701, 934, 3964, 2498, 3738, 3078, 3212, 1734, 3843, 1616, 706, 578, 3353, 261, 2305, 3213, 572, 4357, 1759, 3082, 4547, 2028, 1695, 1216, 2588, 2197, 2742, 1304, 1592, 3205, 4734, 4382, 4289, 2925, 2916, 3831, 3037, 2156, 3898, 3072, 2738, 3606, 1773, 2639, 3874, 4334, 4085, 2638, 4323, 3538, 244, 1379, 3052, 2104, 2774, 3554, 3036, 4212, 535, 3098, 1103, 544, 230, 3931, 3280, 3640, 2330, 3748, 1620, 4503, 2324, 1588, 4402, 182, 1667, 3518, 2966, 1659, 700, 784, 1842, 1257, 832, 2208, 3753, 1435, 1749, 1157, 3763, 1618, 2457, 521, 846, 4588, 3897, 2044, 745, 3961, 1098, 1378, 705, 4564, 4067, 3597, 2255, 2341, 3445, 4380, 1952, 889, 348, 4678, 4429, 2476, 3631, 454, 3825, 3645, 1189, 4691, 736, 3712, 2059, 2166, 445, 3004, 4439, 3076, 1440, 2935, 4376, 1059, 1607, 3721, 1114, 1450, 1246, 2814, 2888, 4213, 4257, 3186, 3798, 3734, 2517, 2136, 2478, 3691, 2696, 2195, 1415, 2487, 94, 1412, 2042, 1906, 3832, 3972, 3324, 710, 4706, 4100, 2359, 316], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 238.2181310239248, 'batch_acquisition_elapsed_time': 0.0011236867867410183})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.637, 'nll': 1.4726951171875, 'f1': 0.6433692697654327, 'precision': 0.6397995224170383, 'recall': 0.6483441023956916, 'ROC_AUC': 0.786865234375, 'PRC_AUC': 0.6764906814241936}, 'chosen_targets': [2, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1, 2, 2, 2, 1, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 2, 0, 1, 2, 1, 2, 1, 1, 2, 0, 1, 0, 0, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 2, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1, 1, 0, 1, 2, 2, 2, 2, 1, 1, 1, 0, 2, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 2, 0, 1, 1, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 0, 0, 1, 2, 0, 1, 2, 1, 1, 0, 2, 0, 0, 1, 2, 2, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1, 2, 2, 1, 0, 2, 0, 2, 0, 1, 2, 1, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 2, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 2, 1], 'chosen_samples': [2111, 2285, 4107, 1392, 619, 322, 251, 1249, 193, 66, 627, 3228, 3765, 3960, 577, 1373, 3479, 218, 220, 971, 4273, 4085, 4336, 826, 1420, 840, 3183, 3593, 1509, 1126, 408, 323, 2232, 2041, 4039, 1680, 297, 343, 2589, 1839, 3092, 3921, 3711, 4147, 1248, 2742, 1213, 3560, 1943, 120, 2372, 1796, 2751, 2000, 3282, 3292, 813, 3336, 1325, 114, 3525, 2395, 4238, 2120, 3580, 520, 3684, 991, 4175, 1466, 2541, 3784, 3458, 4021, 3973, 702, 2779, 4350, 319, 2845, 1368, 1030, 1425, 2780, 3834, 602, 95, 3327, 3827, 662, 3891, 4464, 1496, 1774, 1542, 1266, 2653, 2737, 2486, 4508, 4270, 2115, 3945, 4290, 856, 3085, 1884, 2082, 1748, 2837, 1605, 961, 1230, 3255, 4146, 2160, 1366, 1382, 4276, 2199, 1874, 3311, 1842, 3472, 1821, 199, 1149, 1860, 908, 730, 1220, 574, 786, 825, 1945, 4262, 4401, 3340, 1035, 3775, 4164, 1650, 4137, 181, 3799, 1784, 3350, 4323, 3624, 1365, 1077, 835, 4195, 241, 3574, 2254, 3635, 1802, 2723, 262, 254, 3644, 2191, 115, 2069, 235, 699, 2350, 4327, 2362, 452, 1146, 3892, 2929, 2193, 31, 2821, 271, 1903, 2123, 3982, 3848, 2245, 1598, 2943, 276, 1055, 4410, 4260, 1972, 1507, 3457, 988, 208, 2538, 465, 2565, 3057, 378, 2639], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 275.55215668445453, 'batch_acquisition_elapsed_time': 0.001129623968154192})
store['iterations'].append({'num_epochs': 11, 'test_metrics': {'accuracy': 0.6256, 'nll': 1.6042109375, 'f1': 0.631214800236999, 'precision': 0.6565384389978025, 'recall': 0.6206863178395863, 'ROC_AUC': 0.78662109375, 'PRC_AUC': 0.6518788283130116}, 'chosen_targets': [1, 1, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 0, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 2, 1, 0, 2, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 1, 2, 1, 0, 2, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0, 1, 0, 2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 2, 2, 0, 1, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 0, 0], 'chosen_samples': [1972, 974, 1908, 1062, 2976, 1146, 1300, 1724, 3026, 2362, 4065, 3102, 3813, 1557, 50, 283, 2824, 1811, 756, 1363, 1341, 2868, 2835, 515, 3301, 3564, 1866, 2136, 1017, 4035, 3552, 577, 2150, 3965, 1773, 1091, 2390, 2992, 1226, 1369, 704, 1668, 2127, 1379, 4092, 2605, 4234, 2215, 1847, 2695, 4103, 3811, 1244, 1919, 2053, 2242, 1163, 3505, 3093, 3908, 4286, 598, 4122, 3950, 4179, 3945, 4104, 2777, 1993, 752, 4262, 1508, 535, 1004, 4244, 1047, 2574, 1131, 2023, 1592, 1480, 1506, 3251, 1564, 1894, 2851, 4125, 3745, 2645, 984, 3355, 660, 901, 2445, 69, 3043, 1380, 3509, 649, 4328, 1348, 2730, 3245, 2924, 1406, 3453, 2881, 3085, 609, 3694, 1596, 633, 2817, 3864, 1699, 1674, 311, 2279, 406, 2658, 347, 2962, 4259, 1051, 951, 429, 171, 1929, 3792, 227, 3254, 2052, 2321, 3230, 739, 689, 2206, 2842, 2047, 3160, 3158, 2135, 2142, 3614, 3598, 957, 3983, 213, 1717, 2935, 2414, 2786, 2269, 3768, 708, 136, 1804, 1184, 3690, 534, 1280, 19, 2688, 287, 2291, 4264, 865, 3155, 3361, 2799, 1400, 1279, 1493, 538, 528, 216, 2005, 1556, 255, 4315, 4260, 4239, 3591, 1693, 2325, 147, 4043, 662, 1173, 2259, 635, 432, 854, 2096, 1453, 1683, 1269, 3440, 1818, 2682], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 426.0223479201086, 'batch_acquisition_elapsed_time': 0.0012207604013383389})
store['iterations'].append({'num_epochs': 8, 'test_metrics': {'accuracy': 0.618, 'nll': 1.2508587890625, 'f1': 0.6191482564425844, 'precision': 0.6498995767934698, 'recall': 0.6149661797538529, 'ROC_AUC': 0.78857421875, 'PRC_AUC': 0.616263580380984}, 'chosen_targets': [2, 2, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 1, 1, 2, 2, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 1, 0, 1, 0, 0, 2, 0, 0, 2, 0, 1, 1, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 1], 'chosen_samples': [1092, 3874, 3914, 3735, 816, 1278, 207, 2413, 1938, 107, 2474, 1323, 2279, 2656, 2929, 2804, 2537, 1699, 1760, 1904, 3996, 164, 3012, 1949, 1125, 1859, 3628, 225, 3119, 938, 308, 3925, 237, 3594, 226, 3848, 1542, 454, 2649, 3668, 320, 823, 3544, 3577, 2286, 854, 3070, 1409, 202, 2746, 2457, 509, 287, 2943, 1422, 2984, 3660, 251, 406, 2810, 3287, 3963, 2458, 217, 1306, 2190, 538, 3347, 2834, 677, 2462, 1734, 3956, 386, 2263, 3055, 23, 622, 2645, 1187, 1970, 128, 3514, 2074, 2751, 3928, 325, 743, 3611, 91, 3868, 488, 2104, 13, 2550, 3117, 2004, 2268, 3737, 831, 520, 2137, 3034, 155, 2956, 1785, 3863, 1045, 3797, 865, 3265, 2107, 221, 2826, 1029, 1222, 2053, 1487, 1841, 2035, 2766, 915, 1299, 1811, 2253, 3793, 1973, 2900, 2813, 722, 1124, 706, 1648, 1023, 252, 2754, 1255, 1093, 1529, 383, 307, 1671, 3335, 99, 3020, 3323, 2183, 3808, 3066, 2230, 85, 1179, 3433, 1797, 543, 4074, 312, 1413, 3860, 862, 3158, 3111, 313, 3559, 163, 19, 2572, 1584, 4071, 2861, 1294, 2535, 2918, 3849, 633, 4082, 2831, 1315, 873, 3343, 2938, 3169, 211, 1794, 2492, 2979, 317, 1346, 1129, 2057, 2585, 563, 3182, 3457, 3093, 3207, 3181, 1569, 3624, 679], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 313.3991711968556, 'batch_acquisition_elapsed_time': 0.0007021804340183735})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6308, 'nll': 0.95468974609375, 'f1': 0.6379357416975653, 'precision': 0.6376514953346739, 'recall': 0.6385251293433069, 'ROC_AUC': 0.790771484375, 'PRC_AUC': 0.625795184027333}, 'chosen_targets': [1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 0, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 2, 1, 1, 2, 2, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 2, 2, 1, 1, 0, 1, 1, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 2, 0, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 0, 0, 2, 0, 2, 0], 'chosen_samples': [1859, 3243, 2045, 706, 1709, 3397, 1234, 1073, 2117, 1903, 1671, 2254, 400, 3041, 2451, 3324, 3125, 2001, 918, 1427, 467, 1116, 170, 2171, 3783, 789, 27, 3287, 3044, 1958, 2573, 3791, 811, 1934, 3372, 3524, 2356, 356, 1567, 2056, 1018, 1223, 2968, 3743, 1975, 214, 105, 3289, 1752, 257, 1849, 2158, 1534, 168, 3171, 1607, 2214, 3546, 1206, 1006, 3744, 3149, 402, 2037, 2388, 3116, 1633, 1845, 1495, 2357, 912, 3590, 764, 2514, 3603, 2722, 1868, 3541, 2862, 3761, 3890, 3147, 3649, 666, 1377, 1918, 3803, 3931, 2343, 106, 393, 3217, 2595, 891, 2782, 466, 1305, 196, 1914, 2059, 338, 2295, 272, 1221, 2545, 3786, 1537, 2736, 3191, 629, 1850, 3842, 780, 326, 2730, 1308, 2260, 3884, 1920, 2281, 2488, 3682, 1653, 1725, 1407, 3796, 2748, 3627, 603, 29, 3161, 3671, 1969, 2039, 3850, 2082, 1769, 3638, 3065, 2843, 2817, 3650, 1303, 121, 1689, 1900, 3310, 3543, 3114, 3919, 3816, 528, 2702, 2992, 167, 3224, 2632, 3285, 114, 3098, 1343, 64, 779, 2363, 613, 1056, 460, 3376, 906, 2379, 600, 2630, 3827, 909, 1831, 3561, 1353, 2626, 2118, 3299, 1372, 1955, 2714, 3868, 2239, 3358, 449, 389, 2985, 3589, 2074, 1394, 2205, 434, 3804, 1994, 559, 2259, 3154, 3836], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 200.34358280012384, 'batch_acquisition_elapsed_time': 0.0011072289198637009})
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.6392, 'nll': 0.78942568359375, 'f1': 0.6420577735245527, 'precision': 0.6735178961669751, 'recall': 0.6362810590793672, 'ROC_AUC': 0.80712890625, 'PRC_AUC': 0.6479382539106152}, 'chosen_targets': [0, 0, 1, 1, 1, 2, 0, 1, 0, 2, 2, 2, 2, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 1, 0, 1, 0, 2, 2, 2, 1, 0, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 0, 1, 0, 2, 2, 2, 2, 0, 2, 0, 2, 1, 2, 0, 2, 2, 0, 0, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 2, 2, 1, 1, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 1, 2, 1, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2, 1, 1, 0, 1, 0, 1, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 2], 'chosen_samples': [1216, 51, 539, 1623, 3504, 3600, 3499, 2144, 1673, 1892, 2974, 2297, 435, 1144, 2965, 3453, 2741, 1738, 143, 2845, 2427, 2737, 1162, 645, 2272, 815, 3531, 1335, 2617, 2114, 832, 3459, 714, 3067, 282, 226, 1004, 3040, 3309, 3418, 755, 3338, 2284, 2007, 2548, 2614, 2012, 637, 1807, 1660, 3614, 1695, 1326, 3124, 394, 116, 2783, 845, 1387, 2999, 3355, 2396, 327, 686, 222, 796, 1683, 2013, 470, 3272, 3474, 892, 3218, 108, 2673, 563, 1792, 3473, 2847, 1026, 2204, 3630, 2143, 680, 2003, 3707, 2041, 2765, 1181, 1452, 781, 1608, 589, 644, 889, 1798, 1855, 578, 3333, 1389, 223, 1727, 741, 314, 3589, 3645, 266, 3087, 2133, 3066, 2273, 3586, 2633, 2870, 2821, 1330, 1981, 480, 91, 3017, 316, 3536, 1937, 3389, 933, 30, 3734, 3327, 3708, 1787, 1049, 2590, 2491, 971, 2155, 980, 2885, 3392, 2131, 2571, 201, 1215, 3506, 3135, 1166, 3091, 592, 3370, 155, 1404, 1978, 1359, 1827, 2513, 1044, 987, 3498, 1697, 2015, 400, 2137, 2908, 2690, 823, 98, 13, 1602, 2561, 2170, 585, 3426, 2922, 1317, 2175, 2638, 875, 3489, 2622, 1630, 3303, 1023, 509, 1322, 2727, 2778, 356, 2185, 454, 472, 3511, 1332, 938, 981, 2554, 821, 2059, 3660, 1094, 2928, 3156], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 163.08838407788426, 'batch_acquisition_elapsed_time': 0.0011078971438109875})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6562, 'nll': 0.76868271484375, 'f1': 0.6608536010655869, 'precision': 0.6780016720794738, 'recall': 0.6589782844478004, 'ROC_AUC': 0.831787109375, 'PRC_AUC': 0.6973336796274807}, 'chosen_targets': [1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 1, 2, 0, 0, 2, 0, 2, 2, 1, 2, 1, 1, 2, 1, 0, 2, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 1, 0, 0, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0, 0, 0, 1, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 0, 1, 1, 2, 0, 1, 0, 2, 1, 2, 0, 0, 2, 1, 2, 1], 'chosen_samples': [2429, 2029, 3147, 1615, 2613, 2224, 2001, 2983, 1583, 3058, 2533, 811, 2025, 1116, 2993, 705, 240, 1457, 1429, 625, 1010, 1160, 1274, 501, 2355, 3241, 841, 1452, 666, 430, 2671, 3201, 2878, 2485, 75, 1359, 802, 292, 11, 244, 3191, 2987, 3428, 2111, 899, 2574, 3507, 186, 3424, 3367, 2916, 2965, 3249, 155, 298, 1846, 352, 3086, 2858, 1194, 1706, 2410, 1038, 1895, 3426, 3092, 2997, 1662, 1002, 1094, 1764, 782, 2295, 1192, 3534, 924, 1259, 2177, 630, 1527, 2099, 1726, 5, 2179, 2829, 2845, 1775, 1239, 3132, 3228, 2420, 1346, 1091, 3405, 3513, 869, 2673, 3382, 986, 3358, 2454, 125, 1130, 1512, 752, 2381, 1468, 2815, 1629, 456, 2597, 1422, 2277, 1544, 8, 3456, 1815, 1933, 2375, 127, 330, 1474, 328, 70, 1910, 1394, 2920, 1246, 3167, 1139, 1559, 1039, 3269, 1880, 2215, 1380, 295, 1990, 2884, 1947, 870, 1206, 2107, 1032, 3271, 1599, 216, 3368, 1717, 837, 1069, 3511, 2323, 2530, 1525, 2620, 1146, 1514, 1324, 657, 3430, 3473, 2200, 576, 2208, 215, 2848, 2012, 2703, 3317, 191, 3154, 634, 2903, 421, 175, 2917, 1578, 2119, 1711, 857, 394, 1447, 1152, 2692, 1017, 1716, 2056, 2307, 152, 847, 1129, 3096, 733, 2158, 1698, 1584, 1425, 1714, 2704], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.72181495511904, 'batch_acquisition_elapsed_time': 0.0007053758017718792})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.622, 'nll': 0.97425830078125, 'f1': 0.6288096272855378, 'precision': 0.6350440408947421, 'recall': 0.6296251708832535, 'ROC_AUC': 0.79345703125, 'PRC_AUC': 0.6734115293446569}, 'chosen_targets': [2, 0, 1, 2, 0, 2, 0, 2, 1, 1, 2, 2, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 2, 1, 1, 2, 0, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 1, 2, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 0, 2, 0, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 2, 1, 2, 1, 1, 0, 0, 0, 2, 0, 0, 0, 2, 1, 1, 2, 0, 0, 2, 1, 0, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 1, 1, 2, 0, 0, 1, 2, 1, 2, 0], 'chosen_samples': [2499, 1984, 2976, 2398, 1125, 97, 1857, 3005, 927, 2596, 2313, 1254, 412, 2224, 752, 1287, 576, 2089, 2582, 1502, 792, 1522, 620, 948, 1072, 2042, 2880, 1246, 1612, 2303, 602, 1394, 2759, 1036, 165, 615, 1458, 890, 700, 920, 649, 783, 2143, 1404, 2760, 590, 1116, 1779, 848, 2651, 1361, 1168, 1062, 808, 1145, 1357, 3052, 990, 445, 1042, 2572, 2843, 1723, 626, 755, 2910, 605, 1396, 1957, 22, 2165, 1083, 642, 659, 1010, 1498, 1013, 2838, 294, 1800, 2145, 3316, 964, 2495, 3332, 2900, 2017, 1571, 2730, 3125, 1547, 722, 2674, 2594, 543, 669, 861, 1151, 2904, 668, 2731, 1863, 1177, 2502, 1191, 1303, 2953, 2138, 603, 981, 2318, 1277, 3071, 1891, 965, 2692, 2127, 1164, 3292, 1408, 809, 619, 2917, 2775, 1764, 363, 400, 1231, 2744, 448, 1175, 1766, 2926, 869, 2598, 904, 2206, 1658, 1939, 487, 766, 2219, 3335, 201, 3308, 3041, 149, 2039, 2990, 1960, 2599, 1334, 2662, 3309, 168, 2410, 719, 1944, 2604, 2062, 1660, 348, 2833, 632, 2334, 1886, 1568, 1881, 378, 435, 3245, 1342, 2817, 835, 2963, 2299, 598, 431, 1143, 464, 628, 1014, 317, 2678, 3060, 1549, 340, 1044, 631, 463, 622, 1117, 272, 2714, 2400, 526, 1378, 2116, 286, 3094], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 276.9725746246986, 'batch_acquisition_elapsed_time': 0.0008152741938829422})
store['iterations'].append({'num_epochs': 10, 'test_metrics': {'accuracy': 0.65, 'nll': 1.0165880859375, 'f1': 0.6567353008723779, 'precision': 0.6578931333508927, 'recall': 0.6573869547300917, 'ROC_AUC': 0.82421875, 'PRC_AUC': 0.7146356461998365}, 'chosen_targets': [2, 1, 1, 0, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2, 2, 1, 0, 2, 1, 2, 0, 0, 2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 2, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 0, 0, 2, 1, 2, 2, 0, 1, 0, 2, 1, 1, 1, 2, 0, 1, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 2, 1, 1, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 2, 1, 2, 1, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 2, 0, 1, 1, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 0, 0, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 1, 1, 2, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 0, 1, 0, 1, 1, 0, 2, 2, 2, 1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0], 'chosen_samples': [1079, 2690, 1513, 692, 2180, 217, 2302, 1864, 634, 2700, 1833, 776, 1253, 3041, 606, 1008, 2063, 1359, 92, 1574, 2126, 2972, 2453, 148, 2858, 2194, 1454, 1872, 1758, 280, 397, 304, 2240, 1493, 1871, 31, 521, 1545, 2949, 3024, 2463, 1028, 1913, 2146, 2602, 747, 1137, 357, 3104, 817, 2699, 547, 1325, 1799, 1263, 979, 2659, 798, 2989, 1128, 2309, 26, 35, 1532, 262, 2304, 1752, 1259, 2319, 1092, 2738, 2591, 468, 1969, 2909, 500, 2015, 490, 141, 1075, 2806, 759, 1985, 1734, 249, 1823, 81, 1332, 1720, 2889, 2523, 849, 2510, 2417, 3129, 2456, 2609, 2054, 1085, 2831, 1235, 2223, 1200, 1029, 2131, 1681, 1753, 1459, 390, 1429, 485, 561, 2388, 1761, 1746, 875, 580, 2092, 228, 2462, 1487, 1052, 1751, 1151, 131, 2588, 887, 2267, 451, 1587, 2047, 1046, 2039, 340, 295, 72, 1042, 2049, 2166, 3130, 2578, 956, 810, 422, 2188, 167, 1415, 802, 3053, 2125, 2141, 2601, 269, 1802, 2042, 1926, 1040, 2573, 905, 1666, 123, 2113, 3016, 904, 867, 2274, 126, 2050, 473, 1287, 532, 2303, 705, 631, 1406, 236, 2747, 2004, 1903, 2227, 268, 478, 2213, 1803, 1447, 974, 864, 2464, 1950, 667, 171, 2400, 2208, 1914, 207, 1557, 674, 163, 512, 1664], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 389.68689699005336, 'batch_acquisition_elapsed_time': 0.0011377939954400063})
store['iterations'].append({'num_epochs': 11, 'test_metrics': {'accuracy': 0.651, 'nll': 1.09192998046875, 'f1': 0.6570714367786584, 'precision': 0.6587890778741745, 'recall': 0.6587346675481592, 'ROC_AUC': 0.809814453125, 'PRC_AUC': 0.6611118716004277}, 'chosen_targets': [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 2, 2, 0, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 0, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 1, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 2, 0, 0, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 0], 'chosen_samples': [1202, 1524, 1108, 749, 872, 875, 2806, 1978, 2073, 1508, 180, 236, 157, 429, 2860, 1531, 1570, 80, 1100, 1577, 2741, 251, 1162, 85, 2704, 2697, 1652, 1759, 2569, 2532, 1390, 814, 90, 2006, 851, 1904, 803, 2133, 2689, 1897, 864, 2775, 1355, 1441, 1184, 2291, 1186, 1449, 653, 2573, 1114, 1680, 17, 1607, 897, 445, 1676, 263, 1655, 1012, 1795, 136, 1055, 160, 1557, 1491, 1389, 2265, 628, 2172, 1935, 1551, 1946, 1553, 1429, 2381, 453, 1620, 2812, 2231, 2165, 422, 1354, 1369, 650, 76, 115, 796, 827, 1575, 1075, 165, 1765, 2608, 200, 147, 2396, 425, 1340, 1754, 1908, 756, 1185, 1216, 1275, 229, 1362, 2018, 2714, 2713, 1537, 2143, 241, 1160, 502, 963, 2171, 2847, 1871, 2509, 71, 1756, 769, 2251, 447, 975, 2288, 2844, 221, 2826, 2057, 732, 2706, 1829, 1412, 259, 1627, 194, 2145, 1259, 1053, 2204, 1729, 468, 1604, 1104, 2701, 1442, 2355, 2365, 1687, 2104, 1033, 1906, 1505, 619, 763, 125, 2267, 2512, 517, 1963, 1475, 2149, 60, 2276, 641, 874, 1686, 2853, 2044, 2325, 938, 2195, 102, 1067, 2578, 2450, 1248, 2577, 2081, 137, 1437, 2440, 1775, 2596, 492, 1257, 389, 884, 2637, 2443, 993, 1705, 2066, 2726, 1985, 2572, 2661, 726], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 427.07235133089125, 'batch_acquisition_elapsed_time': 0.0010986127890646458})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.6522, 'nll': 0.85951025390625, 'f1': 0.6607242301878599, 'precision': 0.6667875329268487, 'recall': 0.6578264613112345, 'ROC_AUC': 0.815185546875, 'PRC_AUC': 0.6912803052554518}, 'chosen_targets': [0, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 1, 1, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 1, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 2, 2, 0, 1, 0, 0, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 0, 1, 2, 0, 2, 2, 0, 2, 2, 0, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2], 'chosen_samples': [136, 277, 158, 1347, 251, 324, 644, 471, 2498, 898, 2543, 2533, 2684, 1396, 501, 617, 1945, 114, 757, 1601, 1605, 66, 2695, 1827, 664, 101, 1144, 1032, 874, 734, 1222, 2017, 68, 1244, 2362, 1313, 125, 453, 565, 1841, 1566, 188, 1239, 2604, 2323, 1196, 353, 867, 1561, 1287, 262, 2166, 2347, 242, 239, 2061, 2074, 258, 1736, 1485, 580, 1568, 1813, 111, 2551, 1370, 766, 1696, 606, 568, 1306, 830, 2253, 600, 1388, 657, 817, 777, 2204, 554, 693, 585, 1953, 1847, 389, 1882, 2581, 974, 1617, 1712, 1941, 1181, 838, 823, 2680, 1914, 2068, 422, 421, 2216, 1197, 2359, 10, 2188, 1550, 2606, 209, 1110, 1808, 2341, 695, 641, 976, 2644, 42, 951, 2453, 163, 2450, 1267, 1452, 1440, 2653, 141, 2524, 1487, 2537, 1121, 113, 765, 2319, 680, 1555, 745, 1703, 564, 1274, 1637, 2615, 1126, 2596, 881, 2567, 198, 604, 1502, 217, 1310, 2642, 2103, 450, 159, 117, 682, 1063, 1435, 1247, 1807, 261, 321, 360, 2625, 119, 1795, 1190, 2081, 990, 802, 480, 1211, 1849, 243, 938, 2689, 1293, 145, 1022, 1463, 611, 279, 264, 2093, 1223, 43, 190, 2290, 280, 1973, 35, 2209, 2462, 293, 180, 1366, 425, 1345, 1415, 584, 1921, 2030], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 276.98873966233805, 'batch_acquisition_elapsed_time': 0.0010901708155870438})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6534, 'nll': 0.763338720703125, 'f1': 0.6597114442360272, 'precision': 0.666548215784656, 'recall': 0.6602024178617564, 'ROC_AUC': 0.822998046875, 'PRC_AUC': 0.6801615000322315}, 'chosen_targets': [0, 0, 1, 1, 0, 1, 0, 2, 2, 1, 1, 2, 1, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2, 2, 2, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 2, 2, 1, 0, 1, 2, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 0, 2, 0, 1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 1, 0, 0, 2, 2, 1, 1, 0, 2, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1], 'chosen_samples': [189, 1478, 2439, 683, 421, 604, 1852, 576, 2111, 1427, 1778, 1494, 2214, 2169, 922, 1851, 2094, 1107, 535, 1530, 1296, 2201, 200, 2441, 72, 2367, 1439, 1481, 478, 2106, 1223, 2076, 862, 1221, 528, 1733, 1513, 1567, 2254, 1314, 837, 1096, 1579, 1396, 2450, 1417, 2210, 440, 1642, 75, 1560, 132, 1317, 1151, 1916, 734, 1717, 1456, 1168, 1881, 2219, 14, 1955, 520, 298, 1155, 1570, 929, 1603, 1367, 1556, 1753, 2262, 1887, 2079, 1095, 2392, 822, 502, 2306, 2390, 433, 81, 1484, 353, 1960, 1917, 714, 1173, 956, 1292, 113, 2190, 1165, 954, 2006, 863, 2165, 2480, 2432, 1827, 949, 633, 895, 32, 1514, 1204, 1432, 2274, 1627, 861, 1166, 672, 1196, 1535, 1183, 240, 974, 1629, 1256, 102, 148, 420, 1331, 2402, 2333, 140, 2043, 681, 2256, 1113, 984, 2137, 1973, 108, 1341, 1531, 2418, 204, 2325, 2141, 1100, 1565, 1020, 1449, 680, 968, 1445, 556, 2091, 1103, 591, 1875, 1926, 2189, 1908, 1060, 996, 1294, 1865, 2229, 1725, 367, 1545, 1516, 300, 1517, 485, 2192, 2177, 1004, 335, 417, 427, 2120, 260, 828, 963, 2329, 801, 1491, 2241, 1098, 1430, 1114, 1070, 425, 62, 1387, 2330, 2097, 1920, 1472, 1985, 1695, 121, 1170, 902, 1766, 610], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.23865381116048, 'batch_acquisition_elapsed_time': 0.0007586879655718803})
