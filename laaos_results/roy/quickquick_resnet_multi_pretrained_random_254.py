store = {}
store['args']={'experiment_task_id': 'resnet_multi_pretrained_random_254', 'experiments_laaos': None, 'experiment_description': 'RSNA MULTI:RESNET BN DROPOUT RANDOM (PRETRAINED)', 'batch_size': 16, 'scoring_batch_size': 32, 'test_batch_size': 32, 'validation_set_size': 10000, 'early_stopping_patience': 3, 'epochs': 30, 'epoch_samples': 5056, 'num_inference_samples': 20, 'available_sample_k': 200, 'target_num_acquired_samples': 2500, 'target_accuracy': 0.7, 'no_cuda': False, 'quickquick': True, 'seed': 254, 'log_interval': 20, 'initial_samples_per_class': 20, 'initial_samples': None, 'type': 'AcquisitionFunction.random', 'acquisition_method': 'AcquisitionMethod.independent', 'dataset': 'DatasetEnum.rsna_multi', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': True, 'balanced_test_set': False}
store['cmdline']=['MIP/BatchBALD/src/run_experiment.py', '--batch_size', '16', '--scoring_batch_size', '32', '--test_batch_size', '32', '--validation_set_size', '10000', '--early_stopping_patience', '3', '--epochs', '30', '--num_inference_samples', '20', '--available_sample_k', '200', '--target_num_acquired_samples', '2500', '--target_accuracy', '0.70', '--log_interval', '20', '--initial_samples_per_class', '20', '--type', 'random', '--acquisition_method', 'independent', '--dataset', 'rsna_multi', '--balanced_validation_set', '--min_remaining_percentage', '100', '--min_candidates_per_acquired_item', '20', '--initial_percentage', '100', '--reduce_percentage', '0', '--experiment_task_id', 'resnet_multi_pretrained_random_254', '--experiment_description', 'RSNA MULTI:RESNET BN DROPOUT RANDOM (PRETRAINED)', '--quickquick', '--seed', '254']
# store['USING REDUCED DATASET']=True
# store['Distribution of training set classes:']={1: 8226, 0: 6716, 2: 6216}
# store['Distribution of validation set classes:']={0: 83, 1: 130, 2: 89}
# store['Distribution of test set classes:']={0: 1580, 1: 1965, 2: 1455}
# store['Distribution of pool classes:']={0: 1590, 1: 1926, 2: 1424}
# store['Distribution of active set classes:']={0: 20, 2: 20, 1: 20}
# store['active samples']=60
# store['available samples']=4940
# store['validation samples']=302
# store['test samples']=5000
store['iterations']=[]
store['initial_samples']=[20336, 7953, 840, 19663, 4379, 13075, 6224, 8011, 15868, 12788, 13278, 19490, 5577, 18642, 20707, 5260, 15201, 14991, 15263, 15075, 21093, 16724, 15941, 5456, 3044, 7016, 4993, 13229, 14845, 20638, 20525, 16451, 8324, 15933, 19510, 18753, 10212, 13634, 17718, 3584, 20702, 2561, 7261, 5725, 18013, 6745, 12840, 7496, 11503, 16021, 6814, 6755, 16349, 570, 17262, 15056, 15094, 13781, 5407, 4428]
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.5594, 'nll': 1.659440625, 'f1': 0.5651894396750516, 'precision': 0.5651893431655632, 'recall': 0.5716307843656171, 'ROC_AUC': 0.718994140625, 'PRC_AUC': 0.5622839958978862}, 'chosen_targets': [1, 2, 0, 0, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 0, 2, 2, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 0, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 0, 2, 1, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 2, 0, 0, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 1, 1, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 1, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], 'chosen_samples': [4907, 1874, 503, 4516, 3025, 3639, 2143, 2776, 980, 1890, 1752, 1863, 483, 1013, 3036, 4655, 540, 769, 4179, 4344, 3649, 66, 4419, 3184, 407, 998, 1909, 4360, 1265, 2172, 4293, 704, 873, 2263, 758, 3725, 1241, 3029, 2065, 1614, 3051, 4006, 900, 2568, 404, 3483, 3534, 3275, 4193, 3244, 2404, 1093, 1379, 1358, 2533, 3433, 3493, 2690, 4426, 2610, 3420, 2957, 3652, 1884, 2022, 954, 1232, 3876, 3679, 4619, 2222, 354, 2309, 807, 3085, 4644, 4717, 4225, 799, 230, 214, 383, 2061, 4867, 1174, 2090, 2426, 2488, 1930, 3180, 2121, 425, 1290, 182, 4532, 1871, 1960, 1416, 4754, 4085, 3068, 3660, 3990, 2560, 4676, 2692, 1350, 1288, 2449, 1622, 4013, 552, 3359, 1442, 3546, 4939, 2736, 977, 239, 178, 237, 3694, 979, 442, 59, 318, 3528, 3916, 159, 2973, 1443, 197, 4627, 1386, 605, 2705, 1201, 909, 1579, 2282, 2027, 302, 3338, 3765, 1694, 2732, 3264, 3886, 2146, 315, 2444, 2196, 1107, 4617, 2716, 4172, 4071, 1674, 1304, 4829, 4928, 3227, 1760, 2264, 4301, 3148, 1396, 2429, 3150, 1551, 700, 3054, 1538, 4022, 3391, 2298, 2420, 4140, 3525, 4916, 3464, 288, 248, 4141, 4451, 987, 4599, 4434, 1734, 1799, 1387, 4830, 1062, 1962, 4296, 3123, 3626, 4571, 1613, 3798], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 199.05552749102935, 'batch_acquisition_elapsed_time': 0.0011346647515892982})
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.5838, 'nll': 1.38811357421875, 'f1': 0.5832054043902405, 'precision': 0.5804484025495406, 'recall': 0.6062634613279478, 'ROC_AUC': 0.76416015625, 'PRC_AUC': 0.6239439438620666}, 'chosen_targets': [0, 2, 0, 2, 1, 2, 2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 2, 1, 0, 0, 2, 1, 0, 1, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 1, 2, 1, 0, 2, 1, 2, 1, 2, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 0, 2, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 0, 1, 1, 2, 0, 1, 0, 1, 2, 1, 2, 1, 1, 0, 2, 0, 2, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 0, 1, 2, 0, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 1, 1, 0, 1, 2, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 0, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1, 1, 2, 2], 'chosen_samples': [1478, 2034, 2272, 2570, 3649, 4311, 1375, 2535, 3568, 2285, 1384, 3681, 567, 1745, 4729, 3475, 2313, 724, 3661, 2411, 4580, 2006, 2742, 4126, 2906, 4726, 926, 1968, 140, 2271, 2383, 3052, 4264, 2432, 220, 3062, 1750, 1765, 3756, 1794, 4151, 33, 2572, 4099, 4488, 1184, 115, 229, 2390, 2277, 1974, 280, 4160, 3339, 203, 2162, 3970, 4377, 1569, 1679, 4216, 1144, 1811, 4583, 2230, 378, 2775, 3167, 4132, 3142, 1422, 3895, 3653, 3694, 1893, 2967, 2472, 1674, 4004, 2189, 1620, 3983, 2886, 3546, 3527, 465, 1353, 3584, 2035, 4557, 3891, 3107, 4363, 3938, 703, 1426, 2927, 2524, 2158, 4556, 2041, 1856, 558, 2449, 491, 1731, 4217, 2710, 4031, 2626, 2613, 3278, 1389, 714, 3026, 3805, 1600, 886, 1330, 212, 1285, 1326, 3045, 2786, 4119, 788, 3423, 2882, 2908, 3655, 3152, 1525, 2516, 748, 1015, 4001, 495, 1653, 3313, 4605, 1891, 255, 3489, 348, 879, 1072, 777, 2601, 2784, 4559, 2488, 658, 4275, 3418, 3696, 3432, 4643, 2731, 508, 484, 4196, 4657, 3971, 1884, 4710, 4545, 1167, 2755, 1270, 2679, 2108, 1273, 3665, 3538, 146, 3229, 2826, 3554, 3808, 2751, 3183, 2295, 2043, 2367, 3208, 1037, 1978, 3595, 992, 3100, 2408, 2911, 3515, 2871, 3701, 4067, 3092, 2669, 4409, 3473], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 162.70342705911025, 'batch_acquisition_elapsed_time': 0.0011502946726977825})
store['iterations'].append({'num_epochs': 10, 'test_metrics': {'accuracy': 0.607, 'nll': 1.511996875, 'f1': 0.614439450621529, 'precision': 0.6174129351326646, 'recall': 0.611960798377186, 'ROC_AUC': 0.7822265625, 'PRC_AUC': 0.6832797933564}, 'chosen_targets': [0, 1, 1, 0, 2, 1, 0, 2, 1, 0, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 2, 1, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 2, 2, 1, 0, 0, 0, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 1, 1, 2, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 2, 2, 1, 0, 0, 0, 1, 1, 0, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 2, 0, 2, 1, 1, 2, 2, 0, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 2, 0, 0, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 2, 0, 0, 2, 1, 2, 1, 0, 2, 2, 0, 2], 'chosen_samples': [4039, 378, 4353, 4470, 3803, 938, 3732, 4242, 4238, 1343, 3115, 3932, 2414, 891, 1053, 153, 1184, 4425, 4106, 3391, 3101, 2420, 962, 4142, 2767, 1126, 2812, 1374, 3443, 2569, 966, 2483, 1506, 1396, 3750, 4302, 495, 4118, 2081, 655, 4181, 4186, 3147, 3158, 3103, 3396, 2626, 1205, 2534, 50, 3885, 2623, 2521, 763, 4340, 1322, 2697, 807, 1580, 2060, 1021, 3074, 4172, 2743, 3531, 614, 2791, 1710, 2223, 2817, 1070, 2954, 1433, 1870, 1843, 965, 3247, 2293, 1036, 2298, 2435, 4040, 2379, 4312, 2131, 1822, 3378, 4319, 291, 1552, 1497, 1247, 892, 1863, 3496, 607, 1529, 1967, 4333, 4220, 3757, 423, 328, 2778, 3943, 2997, 3507, 4086, 2106, 3178, 3719, 2020, 360, 1375, 4478, 1955, 3921, 3648, 1989, 4509, 1482, 1146, 244, 3838, 1079, 1041, 2962, 3886, 934, 3491, 2197, 119, 3254, 1662, 4472, 450, 2030, 2347, 3416, 3012, 2911, 3964, 3822, 3258, 798, 3915, 68, 3603, 3205, 1866, 3136, 1963, 1903, 2855, 2900, 3905, 2219, 4346, 768, 1445, 1309, 2444, 456, 503, 347, 911, 4159, 3912, 1266, 2070, 3793, 3790, 3475, 1803, 3854, 555, 3999, 182, 4299, 335, 1888, 4435, 3181, 1464, 2471, 15, 1063, 2369, 382, 3527, 3221, 3834, 2681, 943, 1658, 1132, 379, 544, 2254, 1115], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 388.84486903017387, 'batch_acquisition_elapsed_time': 0.000713166780769825})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.613, 'nll': 1.4325474609375, 'f1': 0.6199658165283545, 'precision': 0.6203562709750288, 'recall': 0.6228243909549838, 'ROC_AUC': 0.777099609375, 'PRC_AUC': 0.6271180519761224}, 'chosen_targets': [0, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 0, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2, 0, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 2, 1, 1, 1, 2, 0, 0, 2, 1, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 0, 0, 2, 1, 1, 2, 1, 1, 0, 0, 1, 0, 2, 1, 0, 2, 2, 2, 0, 1, 1, 0, 1, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2, 0, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 1, 2], 'chosen_samples': [2767, 1536, 945, 649, 2764, 3653, 2752, 2434, 1231, 4122, 3754, 4035, 1664, 4238, 3460, 3167, 4056, 1527, 1826, 3728, 2954, 4291, 3325, 1128, 2749, 1857, 1703, 4168, 416, 2215, 4097, 4250, 3587, 1104, 3956, 3966, 188, 540, 508, 1377, 3746, 1760, 1059, 41, 2472, 3408, 4292, 2649, 1901, 1843, 623, 2338, 1999, 3541, 4080, 591, 2925, 2447, 3664, 3279, 2639, 236, 3779, 1072, 76, 294, 3914, 3880, 592, 1394, 4087, 3273, 2491, 2527, 4315, 1207, 2155, 3502, 4072, 2106, 681, 3040, 4009, 2577, 2750, 279, 462, 1195, 1061, 1089, 2035, 2904, 2843, 1853, 434, 2275, 512, 325, 3314, 4275, 255, 1695, 4324, 4123, 2970, 1400, 3547, 608, 988, 3899, 2516, 2120, 3795, 3062, 2217, 3180, 475, 3000, 82, 549, 2643, 4269, 229, 3817, 3896, 1874, 3715, 4181, 249, 1976, 3953, 4302, 885, 269, 1587, 2894, 3383, 4247, 2600, 3229, 913, 1310, 240, 3532, 4306, 119, 2218, 718, 4143, 3585, 2276, 3901, 4188, 1670, 266, 3434, 3835, 3264, 1439, 1403, 104, 3028, 2223, 1135, 1232, 817, 4175, 1451, 3071, 1134, 376, 1557, 2991, 408, 1913, 593, 2027, 3571, 1086, 3964, 3052, 1606, 3100, 174, 2371, 1208, 2781, 1882, 3716, 787, 2430, 1437, 3139, 3212, 2424, 3076, 102, 2366, 1196, 3939], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 275.769041321706, 'batch_acquisition_elapsed_time': 0.000792438630014658})
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.6246, 'nll': 0.8531490234375, 'f1': 0.6323861662602877, 'precision': 0.6449076318636769, 'recall': 0.625185637516427, 'ROC_AUC': 0.808349609375, 'PRC_AUC': 0.6648723931544}, 'chosen_targets': [1, 0, 1, 2, 0, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, 2, 0, 2, 2, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0, 0, 1, 2, 0, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 2, 2, 0, 2, 0, 2, 1, 1, 2, 1, 2, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0, 2, 1, 0, 1, 1, 1, 1, 2], 'chosen_samples': [3801, 1486, 2463, 3023, 1869, 3754, 3979, 2643, 1931, 3625, 1131, 450, 2356, 1317, 2260, 2566, 3580, 2250, 577, 521, 2069, 167, 971, 2176, 555, 4050, 1212, 431, 3197, 997, 1688, 2239, 1050, 3108, 3775, 2175, 3818, 2471, 260, 1950, 1173, 129, 1681, 2474, 2262, 1518, 681, 1196, 870, 1583, 497, 1303, 964, 1884, 777, 2392, 4047, 1927, 2615, 3419, 828, 1348, 451, 3652, 1516, 2077, 2495, 868, 2070, 798, 2329, 1717, 2752, 2400, 2194, 3118, 2548, 171, 2679, 786, 3057, 2858, 1670, 2633, 918, 2634, 3014, 2137, 1214, 3936, 3509, 4090, 990, 581, 332, 2800, 722, 1548, 3908, 1642, 2045, 1637, 661, 2232, 261, 1951, 3368, 2278, 542, 1569, 3094, 3105, 415, 1157, 2296, 1456, 1079, 346, 2503, 2305, 3149, 1235, 3202, 1891, 3390, 3536, 3682, 2073, 2761, 2589, 1067, 2545, 4057, 3077, 2083, 3281, 1271, 2056, 3673, 1062, 3012, 3967, 3582, 3689, 2698, 2966, 2438, 1701, 3631, 1444, 2967, 2311, 3800, 2570, 124, 2852, 37, 2507, 476, 505, 1006, 4114, 2030, 1381, 4043, 1478, 2630, 3761, 944, 1506, 980, 2727, 1808, 1020, 3952, 4041, 4035, 1369, 91, 2171, 782, 1057, 2793, 229, 2849, 2328, 3445, 1049, 3512, 121, 2777, 1930, 832, 829, 3054, 956, 2613, 1507, 2180, 2005], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 162.86432039598003, 'batch_acquisition_elapsed_time': 0.001167074777185917})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6188, 'nll': 0.95748662109375, 'f1': 0.6264371366299496, 'precision': 0.6254732748653471, 'recall': 0.6279515083937146, 'ROC_AUC': 0.794677734375, 'PRC_AUC': 0.6370118273381058}, 'chosen_targets': [0, 1, 2, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 1, 2, 1, 1, 0, 2, 1, 0, 2, 1, 1, 2, 1, 0, 0, 2, 2, 2, 2, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 2, 1, 1, 0, 0, 2, 2, 2, 2, 0, 1, 0, 1, 0, 2, 2, 2, 2, 1, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 2, 1, 2, 0, 0, 1, 2, 1, 1, 1, 0, 1, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 1, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 2, 0, 1, 1, 2, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0], 'chosen_samples': [1199, 562, 3572, 2538, 2919, 3746, 2867, 3422, 1798, 1776, 3675, 2292, 3926, 1192, 728, 1419, 763, 348, 3433, 1369, 1380, 2281, 539, 2212, 1442, 2095, 3811, 2087, 1086, 1035, 3677, 1350, 979, 2444, 3802, 301, 984, 341, 3629, 3345, 3848, 2890, 1769, 2151, 3822, 2080, 1824, 380, 1412, 3637, 154, 3205, 1896, 2327, 2091, 2955, 3586, 3775, 2203, 3117, 3897, 1164, 3933, 1358, 2242, 3415, 1422, 737, 189, 744, 2730, 618, 3167, 1520, 810, 546, 2228, 2455, 1534, 586, 3742, 3734, 3185, 3819, 3346, 3090, 2102, 2298, 2314, 3927, 1750, 373, 3218, 1923, 3736, 1864, 1112, 3285, 2910, 3580, 2718, 545, 3219, 2100, 2597, 3537, 3764, 3823, 3738, 3869, 1668, 329, 2404, 903, 473, 3463, 3538, 3113, 3571, 653, 2434, 3313, 3323, 991, 142, 1515, 299, 1114, 1583, 2558, 2078, 2983, 1044, 3252, 1262, 1234, 2310, 139, 2586, 1511, 1204, 147, 133, 256, 1736, 2385, 2369, 2326, 367, 3033, 3673, 2868, 415, 227, 2443, 206, 2440, 3443, 3416, 506, 3928, 2606, 1756, 3064, 2481, 3432, 273, 977, 2453, 1497, 2165, 2615, 353, 1732, 1672, 617, 937, 725, 3893, 3898, 3712, 363, 445, 946, 715, 3423, 690, 1544, 106, 1343, 1160, 137, 1411, 223, 2470, 2986, 2156, 1458, 1554, 1008], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.07085382100195, 'batch_acquisition_elapsed_time': 0.0011208397336304188})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.5888, 'nll': 1.23689658203125, 'f1': 0.5888902271370039, 'precision': 0.6439949118544045, 'recall': 0.5754495152400025, 'ROC_AUC': 0.772216796875, 'PRC_AUC': 0.6079078829103634}, 'chosen_targets': [0, 2, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 2, 0, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 1, 1, 2, 0, 0, 2, 1, 0, 0, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 0, 0, 2, 1, 0, 0, 2, 2, 2, 2, 1, 2, 2, 1, 2, 0, 0, 1, 0, 1, 2, 2, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 0, 2, 0, 2, 0, 1, 2, 1, 1, 0, 2, 2], 'chosen_samples': [3039, 803, 2090, 576, 1696, 2737, 243, 3212, 2266, 2657, 1110, 1199, 1168, 1397, 780, 2247, 2672, 78, 1946, 1706, 3024, 1813, 224, 3011, 817, 2874, 3142, 1615, 2116, 2601, 919, 1522, 869, 472, 1527, 3712, 521, 2361, 3027, 377, 319, 718, 3529, 1372, 2083, 1729, 2647, 1723, 2421, 2842, 2089, 643, 953, 3286, 1912, 3714, 2841, 1904, 2698, 3533, 1428, 1099, 1469, 2103, 2298, 816, 1542, 2281, 1430, 2840, 723, 160, 3642, 3264, 2506, 504, 1015, 2237, 2305, 1357, 1976, 2261, 2115, 384, 3587, 982, 833, 623, 1708, 1623, 3515, 1212, 2507, 2322, 1284, 3057, 3201, 571, 27, 1373, 344, 1368, 605, 975, 2835, 220, 2468, 1228, 1369, 440, 2876, 2041, 1674, 364, 2179, 2250, 3612, 736, 498, 294, 3048, 3667, 1969, 1783, 2534, 954, 889, 1135, 2259, 2769, 3692, 131, 1341, 2960, 2422, 1340, 36, 738, 3026, 76, 1537, 3214, 628, 23, 1380, 2852, 1229, 654, 692, 857, 2084, 2390, 1259, 380, 1224, 2142, 3332, 1744, 1884, 2813, 1499, 277, 1094, 526, 2344, 2566, 416, 2356, 590, 1174, 3159, 3616, 2916, 2934, 1177, 2252, 1704, 3206, 1467, 3221, 785, 1383, 1632, 1346, 1310, 2019, 722, 1900, 3209, 913, 107, 2660, 204, 3696, 1779, 905, 1692, 99, 262, 2538], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 276.7546455762349, 'batch_acquisition_elapsed_time': 0.0011055069044232368})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6108, 'nll': 0.899729296875, 'f1': 0.6175218996815244, 'precision': 0.6463791282984869, 'recall': 0.6106648306298056, 'ROC_AUC': 0.774169921875, 'PRC_AUC': 0.654941146595202}, 'chosen_targets': [0, 1, 2, 0, 0, 0, 2, 2, 2, 1, 0, 0, 2, 0, 1, 0, 1, 0, 2, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 2, 1, 2, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 2, 1, 1, 2, 1, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 0, 0, 1, 2, 2, 2, 1, 2, 0, 2, 2, 0, 2, 0, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 0, 2, 2, 1, 2, 1, 0, 2, 2, 2, 0, 2, 0, 0, 1, 2, 2, 2, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 2, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1, 0, 0, 2, 1, 1], 'chosen_samples': [331, 1801, 2685, 756, 156, 2559, 1793, 3015, 696, 412, 707, 3439, 59, 3046, 2285, 231, 1254, 430, 2162, 116, 3348, 426, 1329, 2503, 1733, 1018, 1368, 3272, 234, 86, 3073, 1516, 2989, 3303, 1609, 1883, 3120, 2038, 3474, 1319, 890, 2323, 2095, 1639, 1515, 1626, 2338, 20, 2896, 2838, 3449, 1757, 2877, 1218, 2328, 2407, 3332, 608, 102, 630, 31, 1764, 2771, 2902, 3014, 249, 3241, 1179, 3100, 637, 2463, 2288, 1067, 940, 2344, 1888, 967, 2940, 2105, 2846, 77, 3412, 3467, 2519, 654, 1135, 1802, 1256, 1190, 404, 2061, 1266, 1591, 720, 1243, 1973, 3138, 1820, 1082, 767, 1818, 472, 1572, 700, 1723, 2109, 268, 1497, 2156, 764, 183, 915, 2115, 2007, 1474, 1002, 1126, 658, 1445, 3061, 2079, 1652, 2390, 2909, 220, 289, 3136, 2668, 1131, 2138, 3066, 1551, 2032, 1459, 3104, 2294, 936, 3004, 2046, 2885, 312, 1640, 92, 2683, 1677, 954, 2688, 2566, 2396, 2890, 1528, 2082, 1912, 2470, 2975, 3151, 46, 1841, 2690, 3524, 1049, 1305, 2545, 1975, 1954, 2713, 3485, 356, 554, 478, 871, 252, 1285, 1745, 2308, 1911, 19, 370, 2033, 1655, 2254, 321, 3191, 2640, 237, 1780, 1701, 1736, 1476, 2742, 2882, 836, 2125, 1740, 2242, 125, 496, 1480, 2912, 3312], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.29419721476734, 'batch_acquisition_elapsed_time': 0.0011059679090976715})
store['iterations'].append({'num_epochs': 8, 'test_metrics': {'accuracy': 0.6374, 'nll': 1.0380240234375, 'f1': 0.6443351621240146, 'precision': 0.6453189463910131, 'recall': 0.6446296585921113, 'ROC_AUC': 0.80810546875, 'PRC_AUC': 0.7005926108836507}, 'chosen_targets': [2, 1, 1, 1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 0, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 1, 0, 1, 1, 2, 2, 1, 1, 2, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 1, 1, 2, 0, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 2, 1, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 0, 0, 0, 1, 2, 0, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 2, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 2, 1, 1], 'chosen_samples': [338, 2461, 375, 2375, 1901, 2340, 903, 2067, 2592, 1157, 2617, 3119, 1163, 1453, 1598, 2223, 2876, 3220, 1741, 1434, 1602, 1873, 2495, 2304, 2025, 1929, 2282, 624, 1567, 2499, 948, 2911, 710, 1643, 1569, 2552, 894, 142, 2961, 1223, 2090, 1902, 367, 2353, 3300, 2434, 1725, 1927, 3338, 756, 2211, 804, 2685, 2182, 1770, 2048, 922, 2575, 2736, 2034, 2789, 646, 2953, 1058, 137, 2092, 282, 1660, 1903, 1104, 2844, 2186, 2919, 1435, 186, 776, 2091, 994, 1033, 2992, 3075, 2712, 1515, 928, 150, 1622, 2933, 1857, 2720, 2469, 732, 2388, 260, 2275, 1159, 1226, 900, 2900, 2623, 1735, 1990, 1324, 385, 1054, 2727, 1303, 2229, 1457, 118, 605, 129, 3255, 2568, 1152, 25, 1039, 1808, 2364, 2224, 955, 601, 3317, 2174, 2957, 3326, 352, 827, 1100, 1443, 1559, 1641, 1782, 2913, 3332, 579, 1765, 694, 2023, 1436, 2006, 2213, 786, 1056, 2655, 2887, 508, 944, 2289, 1651, 1987, 2263, 2075, 2553, 3162, 3177, 1726, 853, 860, 2277, 255, 447, 2809, 3004, 1737, 1469, 1605, 2122, 470, 218, 2754, 1881, 1842, 2451, 550, 2728, 1503, 693, 3027, 176, 1055, 2460, 2725, 969, 3256, 2489, 164, 2426, 1394, 1955, 2486, 3020, 1035, 2883, 1891, 525, 1742, 3041, 1183, 1018, 2190], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 315.2391035021283, 'batch_acquisition_elapsed_time': 0.0007924661040306091})
store['iterations'].append({'num_epochs': 9, 'test_metrics': {'accuracy': 0.6424, 'nll': 1.075691015625, 'f1': 0.6424942371632661, 'precision': 0.6656020481422956, 'recall': 0.6436728507283659, 'ROC_AUC': 0.81884765625, 'PRC_AUC': 0.644354292509278}, 'chosen_targets': [1, 1, 2, 1, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 1, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 0, 1, 0, 2, 2, 0, 1, 0, 2, 0, 1, 1, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 2, 1, 0, 2, 1, 0, 1, 1, 2, 0, 2, 0, 0, 2, 0, 0, 1, 2, 2, 0, 1, 0, 2, 0, 1, 1, 2, 0, 2, 1, 1, 1, 2, 2, 0, 1, 0, 1, 2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 0, 2, 1, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 0, 1, 1, 0, 2, 2, 0, 0, 2, 1, 2], 'chosen_samples': [2839, 2790, 1164, 1565, 165, 634, 1498, 2318, 2272, 565, 3014, 1622, 231, 269, 1364, 438, 704, 3031, 545, 1484, 2381, 2140, 1232, 1697, 2427, 2231, 484, 2971, 937, 216, 394, 3103, 914, 1562, 2153, 844, 1671, 2221, 239, 2181, 2460, 2593, 1203, 2150, 1667, 340, 2203, 2537, 980, 1253, 2534, 2750, 246, 809, 2313, 1943, 2461, 2193, 244, 2068, 2779, 1131, 1338, 1834, 2568, 969, 2726, 2247, 302, 1160, 1735, 726, 1432, 201, 2885, 1290, 759, 3073, 2795, 752, 1664, 1644, 1654, 616, 681, 1601, 1529, 1512, 920, 2996, 2649, 1800, 2659, 2072, 1775, 1858, 2146, 1651, 450, 2678, 1689, 2554, 62, 1856, 2249, 1786, 147, 3026, 1747, 766, 1960, 3099, 573, 1148, 2125, 470, 1241, 1539, 2812, 106, 892, 3005, 1211, 2312, 97, 2806, 917, 886, 622, 1404, 2934, 2258, 1645, 821, 2820, 453, 1757, 1673, 385, 434, 2425, 2409, 850, 151, 1326, 1722, 2224, 2199, 2333, 181, 1420, 939, 1235, 1292, 2796, 1155, 1927, 85, 2487, 49, 1316, 2327, 896, 899, 1535, 17, 1569, 1731, 1099, 207, 1197, 2516, 82, 1782, 1116, 2207, 2524, 1680, 1308, 1402, 973, 2469, 2709, 200, 1628, 1230, 817, 3036, 2282, 2605, 2223, 413, 3075, 2540, 1428, 730, 2339, 1352, 2186, 2917], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 351.666238212958, 'batch_acquisition_elapsed_time': 0.0010917740873992443})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6734, 'nll': 0.748104833984375, 'f1': 0.6810131287223528, 'precision': 0.6791195816514203, 'recall': 0.683171938520879, 'ROC_AUC': 0.844482421875, 'PRC_AUC': 0.7387722108560021}, 'chosen_targets': [2, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 2, 2, 0, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 1, 1, 1, 0, 1, 0, 1, 2, 2, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 2, 1, 2, 2, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 2, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 2, 2, 2, 2, 1, 2, 2, 0, 1, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 2, 1, 1, 2, 1, 1, 0, 2, 2, 0, 2, 2, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 2, 1, 1, 2, 0], 'chosen_samples': [2321, 948, 1993, 1173, 1033, 1789, 796, 2184, 513, 2285, 2519, 2609, 2020, 1517, 1357, 1988, 1368, 430, 778, 642, 680, 460, 2398, 22, 968, 2615, 2624, 307, 64, 2792, 2685, 535, 1686, 984, 704, 928, 1839, 2788, 1743, 1151, 2181, 547, 285, 185, 2120, 1465, 1590, 468, 2709, 2741, 954, 1389, 1058, 1887, 2465, 2410, 2341, 2224, 2805, 784, 550, 2563, 812, 1104, 819, 112, 41, 674, 1069, 846, 602, 1600, 2362, 2358, 1986, 657, 1263, 2228, 177, 2646, 1581, 2763, 2055, 2439, 799, 412, 2032, 1942, 979, 2508, 912, 1274, 2264, 1387, 369, 1314, 1507, 926, 467, 2098, 1679, 791, 1914, 2813, 155, 1575, 431, 2737, 2256, 880, 1564, 1365, 187, 273, 915, 523, 231, 447, 971, 586, 325, 2442, 2551, 2591, 387, 905, 1398, 1478, 2505, 924, 2908, 919, 1954, 452, 581, 2874, 716, 1931, 966, 598, 2431, 802, 591, 978, 2231, 2901, 1661, 210, 2718, 1529, 2622, 2777, 1382, 588, 1892, 2106, 1668, 1395, 2167, 126, 2395, 115, 824, 1800, 2227, 2029, 938, 2, 1827, 261, 2915, 271, 1915, 1776, 2338, 2810, 1319, 925, 1024, 1933, 889, 1410, 2006, 663, 1088, 470, 2175, 1374, 1137, 1400, 2692, 1501, 797, 1093, 1923, 1117, 2936, 1127, 2710, 1354], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.3274502917193, 'batch_acquisition_elapsed_time': 0.0011075669899582863})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6598, 'nll': 0.773860888671875, 'f1': 0.6667905138204177, 'precision': 0.6640535701187716, 'recall': 0.6736150943747076, 'ROC_AUC': 0.837158203125, 'PRC_AUC': 0.699413018277445}, 'chosen_targets': [1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 1, 2, 1, 2, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 2, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 2, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 0, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 1, 1, 1, 1, 1, 1, 2, 0, 2, 2, 1, 2, 1, 0, 2, 2, 0, 2, 2, 1, 0, 0, 2, 1, 0, 2, 0, 2, 1, 1, 1, 1, 1, 2, 1, 2, 0, 1, 0, 0, 0, 2, 1, 1, 2, 2, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1, 0, 2, 1, 0, 0, 1, 2, 2, 0, 2, 1], 'chosen_samples': [1792, 621, 436, 467, 2371, 1302, 742, 1846, 1292, 2297, 245, 1424, 2614, 2098, 1863, 899, 608, 1250, 523, 414, 2511, 2477, 617, 1408, 159, 1080, 613, 2369, 2516, 1817, 870, 2609, 1797, 1458, 2099, 586, 170, 2646, 2316, 1085, 2384, 2484, 2694, 168, 1077, 1157, 2697, 1740, 2428, 1999, 2691, 2555, 2326, 1608, 386, 1736, 1689, 310, 967, 686, 2496, 729, 1438, 782, 2727, 2325, 1089, 1039, 147, 827, 1706, 2299, 1422, 1930, 2128, 1597, 2126, 1004, 2461, 211, 1781, 600, 220, 1311, 2289, 113, 2675, 1955, 2136, 84, 1700, 696, 1355, 2478, 2444, 2259, 2030, 1691, 1918, 737, 2624, 2035, 2068, 1694, 1236, 578, 2005, 1304, 191, 7, 520, 1158, 178, 2531, 24, 2426, 377, 2549, 2308, 1774, 956, 2150, 978, 2345, 1937, 1671, 2394, 965, 1350, 2263, 476, 293, 851, 624, 2122, 346, 633, 2089, 642, 2147, 375, 2010, 55, 1613, 326, 1006, 462, 2042, 2207, 1794, 199, 1042, 1857, 779, 1045, 1417, 275, 2418, 439, 636, 2036, 1102, 2392, 649, 409, 638, 2677, 1528, 1724, 1909, 1222, 2153, 391, 2683, 1181, 1124, 1626, 1363, 213, 1942, 2577, 579, 1931, 334, 1905, 656, 2120, 174, 1632, 145, 2571, 1274, 2540, 1679, 204, 1941, 1092, 1281, 80, 1171], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.65290441690013, 'batch_acquisition_elapsed_time': 0.0011048070155084133})
store['iterations'].append({'num_epochs': 10, 'test_metrics': {'accuracy': 0.6482, 'nll': 0.9113279296875, 'f1': 0.6567500842351065, 'precision': 0.658547896965514, 'recall': 0.6585981601777241, 'ROC_AUC': 0.82373046875, 'PRC_AUC': 0.6795655397994302}, 'chosen_targets': [1, 0, 1, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 0, 0, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 2, 1, 2, 1, 1, 1, 0, 0, 1, 2, 1, 0, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 1, 2, 0, 2, 2, 1, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0], 'chosen_samples': [136, 2429, 2498, 2318, 2167, 1469, 1210, 1858, 2177, 2415, 2325, 1509, 1025, 652, 2303, 497, 1887, 932, 2207, 2183, 1632, 639, 1695, 1042, 1192, 963, 304, 1673, 2208, 1119, 797, 2343, 224, 171, 1600, 842, 430, 744, 1697, 607, 886, 2473, 401, 412, 310, 2300, 1938, 1780, 421, 1030, 809, 227, 650, 1942, 1173, 2423, 2188, 2113, 334, 847, 190, 685, 548, 1222, 665, 1973, 2129, 1592, 158, 1513, 1932, 473, 493, 1730, 1847, 201, 610, 442, 509, 576, 434, 540, 1032, 712, 373, 1082, 561, 2330, 2088, 2326, 2234, 2001, 1078, 2253, 1339, 1229, 2077, 877, 1961, 728, 2020, 422, 1390, 1437, 714, 1425, 614, 711, 325, 1135, 1408, 1102, 21, 2428, 30, 767, 1953, 1541, 1370, 525, 2151, 1165, 1948, 496, 1107, 583, 989, 753, 127, 1287, 992, 149, 2102, 2018, 882, 382, 478, 276, 1266, 2530, 1601, 2194, 988, 452, 706, 75, 126, 1728, 2062, 301, 1111, 1418, 1085, 1842, 1886, 189, 2311, 1586, 1545, 531, 211, 537, 238, 2190, 1148, 1727, 1065, 33, 1633, 1676, 1958, 1802, 972, 2027, 1154, 1053, 198, 900, 1639, 2328, 1722, 1617, 693, 488, 682, 1495, 1112, 1829, 153, 425, 1037, 1321, 1862, 2057, 1713, 985, 2308, 1481, 2130, 602], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 391.05741771589965, 'batch_acquisition_elapsed_time': 0.0010968102142214775})
