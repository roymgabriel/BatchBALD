store = {}
store['args']={'experiment_task_id': 'resnet_multi_pretrained_random_58', 'experiments_laaos': None, 'experiment_description': 'RSNA MULTI:RESNET BN DROPOUT RANDOM (PRETRAINED)', 'batch_size': 16, 'scoring_batch_size': 32, 'test_batch_size': 32, 'validation_set_size': 10000, 'early_stopping_patience': 3, 'epochs': 30, 'epoch_samples': 5056, 'num_inference_samples': 20, 'available_sample_k': 200, 'target_num_acquired_samples': 2500, 'target_accuracy': 0.7, 'no_cuda': False, 'quickquick': True, 'seed': 58, 'log_interval': 20, 'initial_samples_per_class': 20, 'initial_samples': None, 'type': 'AcquisitionFunction.random', 'acquisition_method': 'AcquisitionMethod.independent', 'dataset': 'DatasetEnum.rsna_multi', 'min_remaining_percentage': 100, 'min_candidates_per_acquired_item': 20, 'initial_percentage': 100, 'reduce_percentage': 0, 'balanced_validation_set': True, 'balanced_test_set': False}
store['cmdline']=['MIP/BatchBALD/src/run_experiment.py', '--batch_size', '16', '--scoring_batch_size', '32', '--test_batch_size', '32', '--validation_set_size', '10000', '--early_stopping_patience', '3', '--epochs', '30', '--num_inference_samples', '20', '--available_sample_k', '200', '--target_num_acquired_samples', '2500', '--target_accuracy', '0.70', '--log_interval', '20', '--initial_samples_per_class', '20', '--type', 'random', '--acquisition_method', 'independent', '--dataset', 'rsna_multi', '--balanced_validation_set', '--min_remaining_percentage', '100', '--min_candidates_per_acquired_item', '20', '--initial_percentage', '100', '--reduce_percentage', '0', '--experiment_task_id', 'resnet_multi_pretrained_random_58', '--experiment_description', 'RSNA MULTI:RESNET BN DROPOUT RANDOM (PRETRAINED)', '--quickquick', '--seed', '58']
# store['USING REDUCED DATASET']=True
# store['Distribution of training set classes:']={1: 8226, 0: 6716, 2: 6216}
# store['Distribution of validation set classes:']={0: 83, 1: 130, 2: 89}
# store['Distribution of test set classes:']={0: 1580, 1: 1965, 2: 1455}
# store['Distribution of pool classes:']={1: 1845, 2: 1507, 0: 1588}
# store['Distribution of active set classes:']={0: 20, 2: 20, 1: 20}
# store['active samples']=60
# store['available samples']=4940
# store['validation samples']=302
# store['test samples']=5000
store['iterations']=[]
store['initial_samples']=[12503, 6957, 16698, 18870, 6770, 318, 1724, 4481, 4600, 9310, 2446, 5580, 10329, 4919, 13884, 1074, 8058, 18747, 16000, 16896, 3893, 5321, 4343, 7094, 2694, 13368, 568, 19588, 8991, 6533, 17843, 1101, 11933, 8126, 13261, 11004, 20384, 10470, 17957, 11904, 17671, 20250, 13113, 956, 5224, 7586, 15236, 15289, 9008, 16338, 20790, 13798, 17435, 4430, 18521, 14453, 9167, 18290, 15754, 12698]
store['iterations'].append({'num_epochs': 10, 'test_metrics': {'accuracy': 0.5946, 'nll': 1.6920224609375, 'f1': 0.6013656518352418, 'precision': 0.6116365910135149, 'recall': 0.5953000035308401, 'ROC_AUC': 0.76318359375, 'PRC_AUC': 0.648802873995223}, 'chosen_targets': [0, 2, 0, 0, 0, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 0, 1, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 1, 1, 2, 1, 0, 0, 0, 1, 2, 2, 2, 0, 0, 2, 1, 1, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 1, 2, 2, 2, 1, 0, 0, 2, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 1, 1, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 1, 0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 1, 0, 1, 1], 'chosen_samples': [4630, 4838, 1476, 1111, 4349, 2661, 491, 4843, 3529, 2779, 378, 2957, 865, 3336, 3765, 2639, 1386, 653, 2646, 698, 2752, 1974, 2872, 1247, 1016, 4916, 2410, 2226, 4437, 546, 3506, 4905, 738, 4139, 1714, 3120, 3531, 368, 3832, 4280, 4036, 666, 3267, 757, 1760, 109, 4351, 2269, 4538, 2700, 893, 3439, 222, 1534, 3570, 1752, 3262, 863, 1454, 59, 1407, 1845, 366, 904, 172, 4052, 536, 558, 2389, 3706, 533, 3387, 4544, 3414, 4700, 2743, 4686, 822, 211, 2550, 121, 1481, 3998, 3441, 37, 1312, 3133, 4319, 2307, 2841, 1899, 4830, 2680, 4008, 4238, 205, 2612, 2746, 2444, 4416, 2072, 274, 2742, 35, 3780, 1494, 2774, 66, 199, 4412, 1572, 1700, 4523, 153, 1710, 2879, 1622, 2122, 1933, 695, 3187, 130, 767, 3412, 4068, 4320, 12, 3123, 4419, 4909, 4026, 3734, 4605, 4497, 1657, 2583, 2916, 245, 1553, 1355, 636, 1093, 4663, 527, 1628, 2205, 2052, 3839, 3522, 4593, 8, 4370, 3075, 4749, 915, 889, 300, 58, 1662, 1136, 2099, 2133, 1351, 5, 1037, 1681, 384, 250, 1720, 2492, 180, 1206, 3367, 4889, 2797, 3036, 4279, 3021, 4413, 3955, 3732, 2383, 3927, 4886, 3459, 1448, 2172, 2773, 1949, 557, 2689, 3455, 1722, 4262, 488, 1645, 938, 3942, 1358, 3649], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 386.6071818880737, 'batch_acquisition_elapsed_time': 0.0011238758452236652})
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.6046, 'nll': 1.23555576171875, 'f1': 0.6059775589893189, 'precision': 0.6022037400364396, 'recall': 0.6247150340847824, 'ROC_AUC': 0.7568359375, 'PRC_AUC': 0.5843610412414499}, 'chosen_targets': [2, 1, 1, 0, 2, 1, 1, 1, 2, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 0, 2, 2, 0, 2, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 0, 1, 0, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1], 'chosen_samples': [3580, 1491, 2690, 2310, 3630, 3107, 1808, 4191, 2037, 3750, 4652, 1309, 304, 235, 2701, 4311, 4462, 4288, 376, 4180, 3230, 3472, 4721, 2548, 2071, 305, 2108, 1086, 3826, 3655, 4250, 2756, 3061, 825, 3722, 1379, 2908, 1043, 2440, 3788, 4308, 750, 3913, 2383, 29, 3847, 4563, 1966, 1602, 2814, 2736, 588, 4226, 3205, 1411, 3499, 1503, 2671, 4599, 2096, 3140, 1235, 4137, 2475, 1643, 1545, 4272, 1414, 4254, 994, 2464, 2380, 1118, 3424, 230, 3882, 3902, 3285, 4697, 58, 641, 4105, 859, 744, 320, 683, 1188, 1996, 4655, 514, 458, 1289, 1248, 414, 470, 241, 3615, 2542, 1511, 589, 949, 2912, 1293, 3582, 3907, 2823, 1097, 2693, 2442, 3597, 692, 4436, 3932, 2954, 403, 4121, 4678, 1904, 4332, 4516, 2938, 1181, 1577, 3601, 2626, 4412, 550, 944, 2698, 1195, 3706, 993, 860, 915, 2164, 1616, 846, 1323, 2217, 4406, 624, 2496, 371, 559, 4162, 820, 1176, 1613, 837, 3929, 740, 3949, 2054, 810, 186, 3730, 3494, 3311, 464, 4603, 2665, 506, 3810, 1626, 718, 4552, 3465, 1573, 2395, 3663, 3760, 1826, 1507, 1943, 4242, 2253, 199, 30, 2582, 3444, 4576, 2233, 4219, 2807, 1364, 3769, 4225, 1898, 2799, 1715, 2535, 4596, 962, 1810, 4442, 3400, 2356, 326, 109, 2223], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 162.32152183679864, 'batch_acquisition_elapsed_time': 0.0011296938173472881})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6202, 'nll': 1.28088095703125, 'f1': 0.6277971410295683, 'precision': 0.629368695667836, 'recall': 0.6266069666906742, 'ROC_AUC': 0.77783203125, 'PRC_AUC': 0.6600332091422556}, 'chosen_targets': [2, 2, 2, 2, 2, 1, 1, 0, 2, 0, 1, 0, 2, 1, 1, 0, 0, 1, 0, 2, 1, 1, 1, 0, 0, 2, 1, 0, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 0, 2, 0, 2, 1, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 2, 2, 2, 1, 2, 0, 1, 0, 2, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2, 1, 1, 1, 0, 1, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 2, 2, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1, 0, 1, 2, 0], 'chosen_samples': [1947, 936, 3521, 2395, 2686, 293, 1073, 1227, 2909, 496, 4182, 1875, 1936, 1189, 2101, 2029, 3737, 1688, 2813, 438, 3081, 702, 2878, 2487, 1635, 1221, 299, 958, 3667, 861, 2038, 1828, 3422, 777, 3223, 3167, 4233, 4507, 1347, 1944, 4524, 2189, 1735, 751, 4411, 2903, 320, 1368, 1128, 213, 4281, 1340, 4508, 1469, 3412, 0, 1845, 2049, 998, 2593, 3269, 4355, 1837, 3963, 137, 4256, 1230, 1904, 661, 2031, 3584, 2248, 294, 1292, 180, 4101, 281, 2906, 1806, 436, 2934, 1733, 73, 1645, 1654, 895, 1108, 3238, 843, 4128, 4354, 3705, 3992, 4291, 1594, 4400, 1100, 3490, 2058, 3371, 1039, 2017, 1483, 929, 3632, 579, 4164, 812, 2096, 1431, 4186, 3613, 4241, 710, 1611, 979, 140, 3580, 1270, 4512, 2247, 126, 1285, 3033, 799, 3587, 351, 2483, 1763, 2515, 1914, 3437, 3540, 1521, 1834, 1557, 1662, 2059, 1708, 154, 410, 77, 2124, 2158, 1317, 2673, 1370, 2149, 1816, 1154, 385, 752, 781, 4165, 1130, 2990, 2601, 1897, 3885, 3153, 553, 2447, 3182, 672, 4056, 1856, 1337, 106, 3315, 3749, 119, 3535, 4352, 4506, 576, 3680, 913, 3919, 1291, 44, 380, 66, 526, 367, 303, 953, 3565, 1171, 2894, 919, 298, 1984, 3511, 1863, 3046, 4481, 138, 1526, 239, 3178], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 200.82708226330578, 'batch_acquisition_elapsed_time': 0.000704668927937746})
store['iterations'].append({'num_epochs': 6, 'test_metrics': {'accuracy': 0.6344, 'nll': 1.25665986328125, 'f1': 0.6423874247417217, 'precision': 0.6434963842540302, 'recall': 0.6418396141887529, 'ROC_AUC': 0.80517578125, 'PRC_AUC': 0.6485243939114389}, 'chosen_targets': [0, 2, 2, 1, 1, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 0, 0, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 2, 2, 1, 0, 1, 2, 1, 0, 1, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 1, 2, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1], 'chosen_samples': [1370, 90, 296, 3005, 1910, 747, 2405, 2918, 3832, 726, 3437, 710, 847, 58, 3737, 2556, 3846, 3623, 358, 720, 616, 2910, 2248, 1990, 4334, 2015, 904, 701, 1922, 1601, 444, 3994, 518, 693, 3696, 2380, 764, 508, 2578, 3238, 3457, 4090, 3643, 4244, 2067, 3801, 3793, 3648, 459, 677, 1289, 4211, 1026, 355, 1244, 241, 3059, 2529, 573, 1497, 3088, 2495, 3108, 3013, 2599, 2688, 3691, 765, 3244, 3247, 1555, 3666, 3967, 2881, 1913, 2772, 3686, 4187, 3256, 4003, 916, 3136, 206, 745, 1055, 3803, 1331, 905, 442, 1928, 3526, 983, 3081, 2317, 70, 2734, 2311, 2228, 2175, 1498, 402, 3780, 207, 4067, 1558, 4025, 1973, 3436, 4291, 697, 2795, 4101, 412, 3545, 3281, 286, 4188, 3091, 79, 3700, 1909, 1964, 1775, 2977, 3661, 2900, 858, 1917, 1208, 1351, 1128, 4019, 4155, 2970, 3171, 2963, 4152, 4240, 490, 670, 2646, 3309, 360, 1856, 570, 1787, 3947, 1809, 4271, 2903, 2909, 2911, 3839, 1642, 247, 4133, 1312, 3469, 762, 2893, 3186, 1984, 2019, 1552, 4064, 2483, 165, 828, 839, 559, 288, 1556, 1510, 795, 748, 672, 2371, 3071, 1420, 1798, 3877, 2665, 1503, 3567, 3777, 3622, 4030, 4112, 109, 3787, 848, 1285, 4119, 1044, 2686, 3463, 2435, 253, 1554, 3433], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 237.98033671779558, 'batch_acquisition_elapsed_time': 0.0007605091668665409})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.6044, 'nll': 1.35855380859375, 'f1': 0.6090923307716724, 'precision': 0.6040492633132023, 'recall': 0.6197005825443456, 'ROC_AUC': 0.769287109375, 'PRC_AUC': 0.575245752388356}, 'chosen_targets': [2, 2, 2, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 2, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 2, 2, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 2, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 1, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 1, 0, 2, 1, 0, 2, 0, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 1, 2, 2, 1, 2, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 2], 'chosen_samples': [3589, 1158, 775, 3657, 1337, 1030, 554, 1066, 3341, 1903, 56, 2499, 1138, 3626, 3165, 1689, 1781, 3081, 1229, 1109, 699, 270, 1321, 2242, 3483, 1784, 359, 992, 2186, 606, 403, 3038, 3200, 1663, 3646, 3254, 2740, 54, 533, 1311, 1250, 2635, 615, 1885, 825, 3538, 3153, 794, 4028, 3845, 3778, 2714, 168, 3434, 868, 3033, 2450, 1700, 3050, 3910, 3523, 1619, 2642, 1248, 2433, 955, 4023, 151, 2045, 265, 2811, 532, 1611, 1078, 1512, 635, 1924, 3058, 2941, 3854, 779, 2256, 2815, 4000, 3783, 2503, 3773, 116, 375, 2119, 1413, 3508, 3193, 2711, 726, 317, 173, 1198, 2462, 298, 3655, 2342, 1677, 1421, 718, 152, 1070, 14, 514, 2253, 4069, 717, 1485, 720, 2790, 3748, 2277, 3246, 150, 1815, 2273, 1647, 3229, 2586, 3196, 671, 537, 1074, 2839, 1816, 1056, 4059, 3818, 1101, 2794, 1067, 457, 2322, 3175, 3750, 2720, 2515, 1401, 1002, 2779, 3874, 3107, 2383, 1032, 3931, 1024, 2777, 1643, 1226, 3376, 1132, 3345, 1810, 4038, 3232, 1540, 1526, 2830, 790, 1410, 1022, 2845, 2959, 2097, 3230, 1392, 2476, 2599, 80, 1870, 153, 4110, 1537, 815, 4127, 2606, 2795, 1177, 3922, 2679, 235, 1268, 1154, 470, 1523, 3168, 1793, 3585, 2879, 1604, 3592, 1028, 861, 1224, 1592], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 275.8784081400372, 'batch_acquisition_elapsed_time': 0.0011235708370804787})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6236, 'nll': 0.93776962890625, 'f1': 0.6318938764276782, 'precision': 0.6494649997492546, 'recall': 0.6226268133326737, 'ROC_AUC': 0.798095703125, 'PRC_AUC': 0.6586612757500583}, 'chosen_targets': [2, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 2, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 1, 2, 0, 2, 1, 0, 0, 1, 0, 2, 0, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1, 0, 2, 1, 2, 2, 1, 0, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0, 2, 0, 0, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 0, 1, 2, 0, 1, 1, 2, 2, 2, 1, 0, 2, 2, 0, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 2], 'chosen_samples': [2863, 2946, 2180, 3864, 678, 276, 637, 1955, 137, 3330, 3695, 901, 3344, 2711, 2424, 594, 1452, 727, 3820, 741, 298, 2807, 2992, 3780, 3137, 3026, 804, 254, 3077, 1058, 3732, 2123, 1111, 2504, 2593, 1547, 196, 3328, 1270, 1496, 1534, 342, 3484, 782, 2587, 2494, 2678, 843, 425, 3657, 1423, 1838, 3241, 1068, 1139, 3364, 2718, 1483, 1583, 3103, 1208, 1758, 739, 3335, 3851, 965, 2518, 2465, 2687, 870, 2924, 2764, 1837, 3282, 2961, 3916, 2757, 1565, 1559, 2748, 1121, 2887, 2484, 3495, 2410, 880, 1815, 3398, 742, 2596, 1169, 3830, 862, 1064, 2144, 2950, 3936, 223, 652, 2403, 2248, 479, 2150, 2795, 2044, 3774, 784, 863, 1258, 2990, 417, 2640, 1762, 12, 2071, 2343, 2870, 114, 1901, 228, 3411, 1567, 3375, 1816, 187, 2040, 3527, 220, 450, 2669, 936, 2464, 2816, 3541, 3337, 1278, 147, 1791, 2103, 3536, 1106, 1294, 2452, 1742, 108, 3443, 2436, 931, 3230, 698, 3587, 1607, 1036, 3167, 2704, 2947, 364, 1711, 3237, 1940, 655, 404, 2605, 3300, 1397, 1450, 341, 3309, 3338, 2415, 2991, 2907, 1039, 1501, 1673, 2194, 1585, 1381, 389, 46, 2768, 1393, 3853, 1867, 1790, 439, 3083, 3048, 2856, 2890, 3724, 1345, 2930, 3815, 259, 1659, 545, 2883, 526, 1252], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 200.89207531604916, 'batch_acquisition_elapsed_time': 0.0011191670782864094})
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.6476, 'nll': 0.803197900390625, 'f1': 0.65240462543621, 'precision': 0.6476691282873328, 'recall': 0.6628285604454924, 'ROC_AUC': 0.8193359375, 'PRC_AUC': 0.6653262849138104}, 'chosen_targets': [2, 1, 2, 1, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 1, 2, 0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0, 0, 1, 0, 2, 2, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 0, 1, 2, 0, 2, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 0, 1, 1, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 0, 1, 2, 2, 1, 2, 2, 1, 1, 0], 'chosen_samples': [236, 1468, 235, 2176, 2551, 1826, 2845, 378, 2425, 1496, 3688, 2024, 2811, 3284, 1305, 1556, 88, 1009, 3329, 52, 3335, 1577, 3388, 1370, 1846, 3580, 934, 3502, 11, 3729, 295, 3563, 3540, 2128, 394, 2546, 1431, 3647, 1039, 816, 689, 2258, 1900, 2770, 1558, 3102, 3104, 700, 283, 423, 2748, 250, 1436, 2945, 1691, 1611, 2715, 1537, 337, 3698, 1838, 1902, 2010, 2153, 2393, 2303, 1143, 2868, 2702, 989, 1309, 3360, 2271, 1680, 781, 1107, 1102, 3175, 2887, 533, 1020, 3523, 2339, 1467, 281, 1347, 2621, 2420, 2997, 1649, 3139, 253, 3496, 3261, 3736, 1830, 3080, 1541, 1656, 976, 3426, 2203, 3536, 1175, 375, 1063, 2695, 988, 899, 1191, 2180, 440, 1135, 2282, 2181, 2173, 3344, 2657, 3641, 2112, 1251, 1246, 395, 19, 2618, 966, 2512, 2679, 849, 779, 2860, 2209, 3170, 3034, 322, 1589, 3166, 1296, 390, 3477, 2337, 1760, 2477, 2394, 241, 3315, 1795, 802, 303, 2146, 1122, 750, 853, 2611, 1758, 3167, 2292, 2834, 1978, 1037, 2693, 1657, 178, 3385, 2413, 2798, 634, 543, 141, 1094, 3263, 1138, 3614, 2082, 2197, 2730, 2911, 2335, 1817, 1227, 296, 3506, 2777, 381, 2218, 1254, 961, 3414, 2434, 1629, 391, 459, 404, 1847, 410, 1793, 716, 666, 922, 2929], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 163.2217200747691, 'batch_acquisition_elapsed_time': 0.0007315250113606453})
store['iterations'].append({'num_epochs': 4, 'test_metrics': {'accuracy': 0.6442, 'nll': 0.771443408203125, 'f1': 0.6522599992027552, 'precision': 0.6531682783857321, 'recall': 0.6541323115369814, 'ROC_AUC': 0.822509765625, 'PRC_AUC': 0.6988619868175086}, 'chosen_targets': [0, 1, 0, 2, 0, 1, 0, 2, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2, 0, 0, 1, 0, 1, 2, 0, 1, 0, 2, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 0, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 2, 2, 0, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 1, 2, 0, 1, 0, 2, 0, 0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1, 2, 1, 2, 0, 0, 2, 0, 2, 0, 1, 0, 0, 2, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 1, 2, 0, 0, 2, 0, 1, 2, 1], 'chosen_samples': [3035, 3470, 3196, 1642, 18, 442, 2205, 3218, 1295, 411, 400, 2609, 1698, 1061, 623, 3233, 3140, 894, 235, 993, 1862, 979, 2976, 2335, 644, 3490, 1815, 3052, 3072, 695, 1776, 2970, 76, 999, 2338, 322, 3116, 3103, 887, 1721, 3468, 565, 2852, 437, 2538, 1576, 2135, 1511, 2217, 1007, 1791, 1297, 1458, 1775, 3244, 1064, 1159, 2724, 72, 1908, 1452, 631, 2829, 1724, 765, 1795, 1694, 613, 2562, 1003, 2219, 2215, 407, 2277, 1055, 157, 1835, 1683, 1569, 2465, 1553, 3201, 1059, 2955, 3522, 1259, 746, 1228, 2673, 1502, 2760, 2885, 2693, 1917, 2178, 2447, 1136, 150, 2753, 2446, 1938, 2671, 1116, 1036, 1980, 1265, 1380, 2340, 3223, 2047, 1139, 3465, 2218, 650, 1622, 494, 2870, 2134, 2345, 1575, 950, 2960, 2495, 2407, 272, 1291, 3180, 1679, 876, 134, 2057, 3229, 3301, 3328, 2576, 775, 674, 2656, 108, 2950, 3010, 1620, 3242, 1243, 164, 2664, 3191, 1278, 564, 2605, 548, 966, 3252, 811, 3109, 3128, 3026, 2441, 1783, 2097, 834, 1551, 2331, 1593, 1913, 154, 1578, 1233, 2957, 1565, 1999, 937, 2115, 1435, 1148, 2554, 2745, 532, 972, 2564, 414, 59, 277, 3527, 2401, 1997, 761, 2584, 1945, 947, 1638, 176, 1898, 3004, 1485, 839, 1365, 2637, 2718, 608], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 163.79829127527773, 'batch_acquisition_elapsed_time': 0.0011099991388618946})
store['iterations'].append({'num_epochs': 5, 'test_metrics': {'accuracy': 0.6366, 'nll': 0.86201640625, 'f1': 0.6421009647555952, 'precision': 0.6695291853736475, 'recall': 0.630658849231688, 'ROC_AUC': 0.81689453125, 'PRC_AUC': 0.6662883270861647}, 'chosen_targets': [2, 0, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 0, 2, 0, 0, 1, 0, 2, 2, 0, 1, 0, 1, 2, 2, 1, 1, 1, 0, 1, 0, 2, 2, 0, 0, 2, 1, 0, 2, 1, 0, 2, 1, 2, 0, 0, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 1, 1, 1, 0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 1, 2, 2, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2], 'chosen_samples': [810, 171, 3099, 394, 2199, 688, 485, 1562, 711, 2912, 2329, 710, 2141, 2727, 1830, 765, 1533, 1542, 841, 1657, 601, 3005, 2292, 2219, 1326, 551, 1641, 3188, 1319, 1697, 1310, 1464, 919, 3205, 723, 877, 2076, 2340, 2412, 348, 389, 3122, 497, 2647, 1085, 2794, 162, 2689, 717, 2478, 886, 1133, 987, 1137, 1093, 195, 1573, 995, 133, 1780, 180, 2624, 379, 2021, 1150, 411, 2055, 1729, 721, 472, 1469, 1578, 1034, 1725, 1974, 1535, 2302, 2256, 2472, 474, 279, 1598, 2508, 2400, 2745, 20, 2395, 777, 359, 932, 1877, 1781, 2515, 2916, 3160, 876, 3094, 1653, 1764, 2394, 1336, 2567, 839, 298, 71, 918, 2235, 960, 1188, 1770, 1648, 21, 3228, 2725, 1069, 1124, 1550, 2637, 732, 1102, 2661, 2600, 99, 1229, 2082, 2109, 1112, 818, 2574, 3114, 366, 2331, 3102, 1976, 2734, 2533, 2048, 90, 2119, 2229, 1914, 1829, 3257, 53, 1255, 781, 2902, 1878, 2560, 211, 789, 950, 1468, 2568, 727, 2380, 2905, 1095, 1688, 1072, 292, 372, 3315, 3125, 969, 2087, 911, 3032, 800, 295, 1747, 879, 2699, 495, 17, 1870, 3272, 416, 2404, 3338, 153, 1287, 1318, 127, 1596, 3049, 1784, 718, 3143, 3289, 1944, 2801, 1997, 1627, 2879, 3086, 650, 1894, 2493, 966], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 201.90202458808199, 'batch_acquisition_elapsed_time': 0.000916594173759222})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.6554, 'nll': 0.83508271484375, 'f1': 0.6634111516760689, 'precision': 0.6753384399643502, 'recall': 0.6563597625017474, 'ROC_AUC': 0.822265625, 'PRC_AUC': 0.7141115829562661}, 'chosen_targets': [1, 0, 2, 1, 2, 2, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 2, 2, 1, 2, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 2, 1, 0, 2, 0, 2, 1, 0, 1, 2, 0, 0, 0, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 0], 'chosen_samples': [2476, 2291, 2071, 3101, 1570, 0, 748, 2837, 1189, 431, 3067, 2786, 2625, 2517, 2702, 1191, 2662, 3043, 1140, 2603, 1740, 955, 44, 2392, 233, 1790, 1192, 2975, 2840, 2716, 791, 1405, 68, 1463, 2838, 437, 346, 549, 2981, 2935, 2833, 2755, 502, 1379, 1080, 613, 1288, 2761, 2078, 2772, 1672, 1178, 878, 3130, 377, 2722, 3005, 17, 777, 286, 2213, 533, 1443, 1908, 2046, 2441, 1630, 2224, 3122, 3000, 2824, 2433, 2380, 3102, 2508, 623, 22, 682, 1602, 1158, 602, 67, 20, 747, 462, 1211, 2789, 983, 2462, 3022, 956, 2212, 1321, 1290, 2052, 1611, 775, 997, 2356, 2471, 603, 2494, 3076, 1669, 1551, 1007, 1732, 1487, 2788, 1046, 1123, 2122, 1208, 2681, 223, 2201, 2419, 467, 1273, 610, 2633, 1042, 169, 786, 2364, 1784, 2684, 702, 3124, 1099, 414, 2233, 1754, 1163, 2631, 183, 2255, 426, 1633, 173, 615, 1890, 48, 2369, 896, 1212, 3133, 1153, 1763, 2959, 1553, 1805, 2025, 2119, 675, 2391, 2260, 2184, 2598, 2040, 410, 635, 255, 277, 2463, 2234, 2465, 599, 585, 1374, 1065, 913, 1626, 1851, 2331, 1928, 808, 2188, 1297, 2355, 812, 71, 2451, 570, 306, 833, 1788, 1117, 754, 636, 2349, 957, 316, 2263, 1563, 598, 58, 763, 1685, 391], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 277.0504660909064, 'batch_acquisition_elapsed_time': 0.0007035559974610806})
store['iterations'].append({'num_epochs': 7, 'test_metrics': {'accuracy': 0.6392, 'nll': 0.874161328125, 'f1': 0.6422034890378158, 'precision': 0.6868211371046352, 'recall': 0.6297058046458108, 'ROC_AUC': 0.804443359375, 'PRC_AUC': 0.6823967087812549}, 'chosen_targets': [0, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 0, 2, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2, 2, 0, 1, 0, 2, 1, 2, 2, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 2, 2, 1, 1, 1, 0, 0, 2, 1, 2, 2, 2, 1, 1, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 0, 1, 2, 1, 0, 0, 0, 2, 2, 0, 1, 1, 0, 2, 1, 2, 1, 0, 1, 2, 2, 1, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 0, 2, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2, 0], 'chosen_samples': [1107, 758, 123, 624, 2138, 1935, 709, 744, 639, 2125, 2424, 2860, 655, 2839, 967, 1388, 1233, 1031, 47, 2361, 2802, 145, 2045, 2731, 162, 464, 2559, 27, 2319, 683, 580, 186, 2673, 2481, 1592, 2111, 1837, 2610, 2279, 25, 2153, 1238, 1443, 2205, 1289, 2172, 478, 271, 132, 83, 2616, 1160, 1834, 2232, 1261, 1102, 1685, 2602, 2523, 1308, 1990, 2641, 327, 961, 1612, 2023, 1444, 1697, 1725, 1085, 1228, 2440, 2810, 1532, 1389, 947, 323, 2780, 1101, 1270, 73, 907, 1194, 650, 462, 1410, 589, 97, 959, 2584, 2393, 614, 1000, 1531, 1396, 1018, 916, 230, 1621, 1975, 1694, 1731, 2059, 383, 860, 2828, 1541, 1240, 1043, 2804, 1533, 2595, 1071, 993, 663, 2156, 2774, 2908, 89, 2770, 902, 785, 2590, 850, 2390, 837, 571, 1885, 2876, 822, 730, 1487, 1299, 1320, 200, 2237, 294, 1933, 125, 213, 581, 1342, 2166, 1907, 2863, 1119, 2181, 2249, 9, 1714, 2725, 2163, 1381, 2032, 1341, 788, 2179, 1553, 943, 2230, 193, 2030, 1473, 2219, 2556, 1035, 2639, 1066, 2395, 154, 2451, 1854, 71, 1588, 1680, 2123, 2582, 2931, 657, 2431, 1843, 2221, 234, 1594, 548, 901, 830, 930, 2101, 1984, 62, 372, 2657, 2682, 2934, 179, 2856, 42, 1540, 523], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 277.08845982095227, 'batch_acquisition_elapsed_time': 0.0010902159847319126})
store['iterations'].append({'num_epochs': 6, 'test_metrics': {'accuracy': 0.653, 'nll': 0.7953279296875, 'f1': 0.6590475616256675, 'precision': 0.657260779271148, 'recall': 0.6694668719202689, 'ROC_AUC': 0.822265625, 'PRC_AUC': 0.6877186284399823}, 'chosen_targets': [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 2, 0, 0, 2, 2, 0, 1, 1, 0, 1, 1, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 2, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 2, 0, 2, 1, 2, 2, 1, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 2, 2, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 1, 1, 2, 0, 1, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 1], 'chosen_samples': [1403, 412, 2189, 2089, 601, 1185, 914, 1232, 1169, 423, 1965, 254, 1158, 2170, 1141, 102, 906, 2360, 1338, 2299, 2404, 2578, 596, 1312, 1138, 278, 754, 1705, 1477, 1441, 2590, 1026, 67, 1855, 1139, 34, 1417, 1618, 413, 1823, 1936, 2162, 1414, 1247, 682, 2284, 910, 1654, 2383, 421, 285, 1147, 1046, 1490, 2597, 1766, 968, 1157, 1834, 1547, 91, 1663, 1635, 1830, 288, 2428, 1650, 1728, 1914, 1388, 2124, 1470, 1431, 1153, 2298, 1659, 1971, 473, 750, 1999, 13, 647, 1094, 1346, 2319, 1987, 755, 2412, 1944, 2099, 2181, 1704, 1739, 1134, 1741, 2465, 2021, 1003, 1677, 820, 1828, 2054, 807, 725, 1943, 1993, 315, 728, 2564, 773, 827, 816, 1768, 2013, 2084, 458, 743, 582, 964, 246, 1808, 336, 1688, 1240, 776, 431, 2512, 651, 1057, 1378, 241, 1637, 996, 471, 1404, 12, 414, 1004, 1334, 2661, 69, 1982, 1305, 896, 1497, 698, 786, 355, 2697, 2665, 2265, 1018, 1085, 2105, 311, 1289, 572, 4, 1472, 117, 361, 1846, 334, 1210, 1236, 1969, 1941, 514, 2659, 2022, 1492, 2357, 2071, 419, 1863, 105, 465, 1957, 2680, 1355, 2714, 2096, 795, 1586, 2443, 1156, 885, 1053, 717, 329, 1316, 1125, 2515, 2425, 1919, 1443, 649, 1515, 367, 2413], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 239.1816155309789, 'batch_acquisition_elapsed_time': 0.0006898422725498676})
store['iterations'].append({'num_epochs': 8, 'test_metrics': {'accuracy': 0.6566, 'nll': 0.86494609375, 'f1': 0.6646369385466588, 'precision': 0.6778544688018772, 'recall': 0.6571193912078982, 'ROC_AUC': 0.83251953125, 'PRC_AUC': 0.6767649952087643}, 'chosen_targets': [2, 1, 0, 0, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 0, 1, 2, 0, 2, 1, 2, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 1, 2, 0, 2, 1, 2, 1, 2, 0, 0, 2, 0, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 0, 2, 1, 0, 1, 2, 1, 2, 2, 0, 2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 2, 0, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 2, 2, 0, 1, 2, 2, 0, 2, 2, 1, 2, 0, 2, 1, 0, 1, 2, 1, 2, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 2, 2, 0, 0, 0, 2, 1, 0, 2, 0, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0, 1, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 1, 0], 'chosen_samples': [1252, 173, 1030, 888, 67, 524, 1820, 608, 1509, 2483, 1290, 2003, 2091, 2074, 1735, 2062, 1607, 1034, 1077, 409, 2442, 1597, 1733, 1388, 84, 1278, 1336, 1492, 1275, 2402, 1210, 1854, 2033, 157, 897, 1692, 61, 872, 612, 1419, 2328, 262, 1262, 429, 677, 1805, 407, 2290, 1379, 1173, 2506, 2208, 716, 1411, 653, 2387, 930, 411, 1259, 2211, 557, 2225, 2138, 395, 2534, 1348, 1706, 2533, 854, 2237, 2113, 1688, 1997, 691, 260, 139, 103, 1425, 682, 1452, 1192, 62, 1791, 1819, 670, 2055, 1202, 379, 567, 1627, 2175, 2187, 244, 324, 1583, 197, 1809, 1002, 1355, 43, 819, 1596, 376, 543, 726, 24, 1239, 671, 735, 2146, 306, 1831, 1198, 1477, 1543, 1932, 1879, 211, 276, 875, 1513, 1384, 907, 829, 2355, 1320, 117, 332, 1485, 1663, 1814, 2199, 1495, 2273, 896, 1587, 1161, 71, 140, 1576, 302, 1996, 1554, 356, 1519, 2230, 2145, 2029, 2429, 2495, 248, 895, 1289, 1630, 1415, 1919, 2179, 1764, 1911, 1825, 949, 130, 227, 647, 2241, 2414, 2231, 864, 621, 1981, 2345, 2206, 1778, 2193, 1863, 406, 187, 1920, 1957, 455, 2260, 1165, 1269, 2101, 1531, 1324, 843, 2303, 419, 33, 1654, 457, 381, 656, 2148, 1215, 1311, 1506, 1768, 1795], 'chosen_samples_score': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'chosen_samples_orignal_score': None, 'train_model_elapsed_time': 315.77320740604773, 'batch_acquisition_elapsed_time': 0.0010820659808814526})
